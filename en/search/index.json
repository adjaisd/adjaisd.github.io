[{"content":"National Day Records in 2025 Today is the last day of the National Day holiday, and work will resume tomorrow. Taking advantage of the last day of the holiday, I am recording my life during this National Day holiday and summarizing my recent life status.\nLife During the National Day Holiday During this National Day holiday, I mostly stayed at home. My parents arrived in Hefei on the first evening. The annoying part was that in the following days, my parents kept trying to set me up with online dating matches. On the fifth day, both sets of parents and the children had a meal together. Both sets of parents were quite satisfied, but the match was not my type, and there was no further contact afterward.\nOn the sixth day of the holiday, it was the Mid-Autumn Festival. The whole family stayed at home and had a reunion dinner. On the seventh day, my parents returned to their hometown. I played games with my classmates, and on the eighth day, I stayed alone in my room to summarize this holiday.\nOverall, this National Day holiday was quite uneventful. The issue of my parents urging me to get married has temporarily come to an end, and they will not interfere too much in my life anymore. I can return to my three-point-one-line lifestyle.\nSummary of Recent Life Status Since July, work has become busy, and I have gradually taken on some of the leader\u0026rsquo;s tasks. Every week, I summarize the issues from the previous week or share some development experiences and team collaboration norms.\nDue to the increased time spent on work, I need to take time to summarize all members\u0026rsquo; issues. However, I often encounter situations where members do not participate. Therefore, in the absence of anything to report, I can only take time to organize development documents or learn some new technologies.\nOutside of work, I have started long-distance running and have persisted for more than two months, accumulating nearly 100 kilometers of running. I aim to complete the 100-kilometer achievement this week and will continue to persist in the future.\nUpdated on 2025-10-08\n","date":"2025-10-08T11:39:09+08:00","image":"https://adja.com.cn/p/national-day-records-in-2025/cover_hu_8345905b907ae457.jpg","permalink":"https://adja.com.cn/en/p/national-day-records-in-2025/","title":"National Day Records in 2025"},{"content":"Long Term Planning In the past, I was always anxious, thinking too much, and struggling too much, but I didn\u0026rsquo;t achieve enough outstanding results. Now I think that this anxiety may be caused by not having a clear goal and plan.\nIn the next period of time, I will try to use some efficiency tools and make long-term plans. In addition, I will pay attention to exercise, maintain a fresh appearance, go out more often to meet like-minded people, and hope to find a partner who can promote each other.\nNext, I will update this plan regularly to see if I am moving towards my goal.\nTime Planning Completion 2024.11~2025.2 Rust basics √ 2025.3~2025.4 Dart basics √ 2025.4~2025.8 Learn flutter 10% 2025.4~2025.11 Learn godot 0% 2025.6~2025.11 egui 30% 2025.6~2025.12 Find friends of the opposite sex 0% Updated on 2025-04-20\nNow it is May 6, 2025, the Labor Day holiday has just ended, and the server I bought during college has expired. I have been exploring Cloudflare\u0026rsquo;s Pages and Workers, and to reduce hassle, I will host the website on Cloudflare in the future, while continuing to use the original domain name.\nIn addition, I was using Hugo version 0.128.2 to build the website, and the latest version has been updated to 0.147.1. The theme has also changed a lot, so I took the opportunity of this holiday to update everything.\nRegarding the plan to learn Flutter and Godot, I compared other rendering engines and felt that technology is developing too fast. I still need to delve into the underlying layers, so I will proceed with the original plan for now.\nIn terms of finding friends of the opposite sex, I tried online dating once, but I felt that the other party was quite passive, so I guess we can only remain strangers. My parents also talked to other parents online, but it seems that most of them didn\u0026rsquo;t work out, so I\u0026rsquo;ll just let fate decide.\nMy parents came to my workplace during the holiday, and our family went back to our hometown to have some fun. The town has changed a lot, with new houses waiting to be occupied and tourist attractions under construction. I hope that my hometown will get better and better in the future.\nUpdated on 2025-05-06\nToday is May 25, and two weeks ago, the weekly holiday was changed to a double weekend, giving me more time to invest in things I am interested in.\nI read some articles online about graphical user interface development, such as app development frameworks (Flutter, React Native, Tarui, etc.) and game engines (Godot, Unity, Cocos, Bevy, etc.). I realized that my original idea was too naive, wanting to make both apps and games, so I hesitated about which engine to learn and even downloaded Unity.\nIf I want to produce results quickly, I need to give up Godot and invest all my time in Flutter, while also casually learning about Rust-related development in my spare time.\nUpdated on 2025-05-25\nIt is July 21st, and more than two months have passed. Two months ago, after comparing various GUI frameworks, I decided to temporarily give up flutter, and have been thinking about egui afterward.\nSince asynchronous waiting operations are not allowed in the loop of egui, channels must be used to transfer data. When an event occurs, the app retains the receiving channel, creates a thread in the background to process the data, and sends the data to the app through the channel after processing. Each time the app loops, it checks the receiving channel data and updates the interface after receiving the data.\nWhen trying to integrate simple asynchronous operations into egui, it is also necessary to solve the problem of multi-threaded shared resources. Use Arc\u0026lt;Mutex\u0026lt;T\u0026gt;\u0026gt; to share data; if read and write operations are performed simultaneously in multiple threads, RwLock\u0026lt;T\u0026gt; needs to be used to share data.\nIn addition, code reuse and structure also need to be considered. Use the App trait of egui to define the structure of the application, and use egui::Context to manage status and events. Recently, I found a project for reference, hoping that it will be helpful for subsequent development.\nUpdated on 2025-07-21\nIt has been a month since the last update. Due to being responsible for tracking and handling issues within the team, my spare time has been significantly reduced. If I work overtime until 9 pm every night, I go for a run in the nearby park. Looking back at my check-in records, although I can\u0026rsquo;t stick to it every day, I have been exercising an average of 3 days a week since mid-July, and I will continue to maintain this habit.\nIn my spare time, I have used egui simply and found that if I design complex functions poorly, maintaining the code can be quite laborious. Therefore, I started to pay attention to Bevy, whose design philosophy and ECS architecture enlightened me. Recently, I have roughly understood the basic concepts of Bevy, and I will try to use Bevy to create some small projects in the future.\nUpdated on 2025-08-24\n","date":"2025-04-20T09:34:35+08:00","image":"https://adja.com.cn/p/long-term-planning/cover_hu_f6d19d11acdef439.jpg","permalink":"https://adja.com.cn/en/p/long-term-planning/","title":"Long Term Planning"},{"content":"Remote Networking for Online Games After graduation, my classmates all went to different places to study and pursue their careers. They would occasionally play a game of Warcraft during holidays, but since they were in different provinces, it was a bit troublesome to connect to the LAN game.\nDuring this period, I tried to use free networking tools, build my own transit server, and use Dandelion networking. Through comparison, I hope everyone can find a networking method that suits them.\nEasyN2N Or N2N Since I used EasyN2N at the beginning, the experience was pretty good, and I was able to learn some network knowledge from the relevant community.\nHowever, since the transit server of EasyN2N is free, when everyone is using it, the transit server will be overloaded, resulting in high latency or even failure to connect. After graduating and returning to my hometown, the network there is poor, and I often get disconnected halfway through playing.\nIn addition, EasyN2N is often accidentally deleted by antivirus software, which may also cause disconnection in the middle of the game, so it is recommended to use it through the command line instead of using its own visualization tool.\nFor related usage, please refer to this article\nBeirui Dandelion Beirui Dandelion is a paid networking tool, free for up to 3 people. If you want to network with more than 3 people, you need to buy a package.\nThe free version of Beirui Dandelion cannot set the IP of the virtual LAN client. Some games, such as Warcraft, require packet capture and analysis. It can be found that client B cannot receive the UDP message broadcast by client A, so you have to use the network debugging assistant to assist in creating a room. The following are the specific steps:\nAssume that there are two computers, A and B. The IP address of computer A is 172.16.3.130, the IP address of computer B is 172.16.3.150, and the subnet mask is 255.255.252.0.\nIf computer B creates a room as the host, and computer A joins the room as the client By capturing packets with Wireshark, it can be found that after computer B creates a room, it will continue to broadcast f732100001000000010000000c000000 to udp port 6112. Due to limited time, the meaning of the message will not be analyzed.\nWhen computer A scans the existing room, computer A will broadcast f72f1000505833571a00000000000000 to udp port 6112. Since A and B are not in the same network segment, computer B cannot receive the broadcast of computer A, and A cannot know whether there is a room.\nNext, we use the network debugging assistant to send a udp broadcast packet for scanning the room from computer A to computer B. Assume that the message msg (including the number of players, map information, etc.) is received.\nThen, send the content of msg to computer A on computer B, and computer A can join the room.\nSummary If there are fewer clients to be networked, N2N and Beirui Dandelion are both low-cost networking methods.\nIf there are further needs, such as a large number of people in the room, or a more stable network is required, if the players are mainly concentrated in a few areas, you can consider building your own transit server. If the players are widely distributed, you can consider purchasing the Beirui Dandelion package.\nReference https://bugxia.com/n2n_launcher_param\nhttps://www.cnblogs.com/flying_bat/archive/2008/06/24/1228627.html\n2025-02-22 Update\n","date":"2025-02-22T19:21:36+08:00","image":"https://adja.com.cn/p/remote-networking/cover_hu_78ce9c8e0514c0eb.jpg","permalink":"https://adja.com.cn/en/p/remote-networking/","title":"Remote Networking for Online Games"},{"content":"Summary of 2024 It has been more than a year since I started working. During this time, I have experienced a lot and learned a lot. This article is a summary of 2024.\nWork My work mainly involves firmware development for microcontrollers. After a year of training, I can basically handle this job. In this year, I have learned a lot, such as teamwork, development tool usage skills, and the use of common peripherals of microcontrollers.\nDuring this period, I also encountered many problems, but with the help of leaders and colleagues, they were all solved. Every time I encounter a problem, I will first think about it myself, and then think about how to improve it on the basis of mastery, such as improving the readability, reusability, and convenience of the code. In every detail, I try to do my best.\nIn my spare time, I also tried to learn some new technologies and tried to apply them to work, such as using Renode to improve the efficiency of firmware development, trying gitlab\u0026rsquo;s CI/CD to compile firmware, etc. Although I have made a lot of efforts, the effect is not very good, mainly due to the lack of participation of members, too much work, too little time, etc.\nLife Because I went to work in a different place alone after graduation, everything in life has to be taken care of by myself, which is a challenge for me.\nBecause I live in a very remote place, and because of my personality and other reasons, I basically stay at home, read novels, play Warcraft, and tinker with some technology in my spare time.\nIn the first half of the year, when I was not busy, I migrated my blog from hexo to hugo, which makes it more convenient to write articles and easier to maintain.\nIn addition, if I have time, I will play games with my classmates, which can relax and keep in touch with my classmates.\nOutlook for 2025 Although I found a job in 2023, which was a year of graduation and unemployment, considering that the number of graduates is still increasing in the future, the future competition will be more intense. In my spare time, I need to continue to maintain sensitivity to technology and have the opportunity to meet more people.\nIn addition, it is troublesome to set up a network in different places when playing games with friends. Next, I will try to refer to some open-source projects and develop a simple networking tool.\n2023-02-02 Updated\n","date":"2025-02-02T12:38:52+08:00","image":"https://adja.com.cn/p/summary-of-2024/cover_hu_3b521bf98819ec8b.jpg","permalink":"https://adja.com.cn/en/p/summary-of-2024/","title":"Summary of 2024"},{"content":"Teamwork Using Git It\u0026rsquo;s been a long time since the last update of the blog. This time, the content of the update is about how to use Git for teamwork. This article mainly introduces the workflow of teamwork.\nBasic Tutorial This article assumes that you have a basic understanding of Git. If you are not familiar with Git, you can refer to some basic tutorials about Git first such as Liao Xuefeng\u0026rsquo;s Git Tutorial.\nIf you are not used to Chinese, it\u0026rsquo;s recommended to read the official Git documentation: Git Documentation.\nIf you have basic Git skills, you can continue to read this article to learn how to use Git for teamwork. Before reading this article, you can also read Pro Git. Fortunately, the book is free to read online and available in many languages.\nThen, let me introduce the workflow of teamwork using Git.\nTeamwork Workflow I introduce the workflow mainly based on Gitlab.\nIn GitLab, there are 5 roles for repository members:\nGuest: can only view repository contents, but cannot perform write operations;\nReporter: can view and clone repositories, but cannot perform write operations;\nDeveloper: can perform write operations, but cannot manage project settings;\nMaintainer: can manage project settings and members;\nOwner: has all permissions, including deleting projects.\nSuppose there is a project with 5 team members including project manager (1 person), developers (3 people, 1 of whom joined midway), tester (1 person);\nThe roles and responsibilities of these 5 people are as follows:\nProject Manager: Owner Developer #1: Maintainer (responsible for developing and reviewing code) Developer #2: Developer Developer #3: Developer (joined midway) Tester: Reporter Before Developer #3 joined, the project development was all done collaboratively within the team, and the code should be submitted to a repository.\nAfter Developer #3 joins, the project involves cross-team development. Developer #3 should fork the repository. If using GitLab, merge the code into the upstream repository (the upstream repository is the forked repository) through Merge Request (MR for short).\nThe following is the workflow description of GitLab Flow.\nThe project manager creates a repository, submits the requirements document, and adds team members as Developers The initial submission is as follows:\n1 2 3 4 5 6 git init . touch README.md #This article briefly introduces the project background and function git add README.md #Add README.md to the staging area git commit -m \u0026#34;first commit\u0026#34; git remote add origin https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/xxx.git #Add a remote library, change it to your own remote library here git push -u origin master Next, submit the requirements documents.\n1 2 mkdir docs #创建docs目录，在该目录下添加需求文档 touch docs/requirements.md #采用markdown格式记录需求文档 Open the docs/requirements.md file and complete the requirements document. After writing it, do the following:\n1 2 3 git add docs/requirements.md #Add the requirements document to the staging area git commit -m \u0026#34;[docs] Add requirements document\u0026#34; git push origin master Developer #1 submits technical documents and creates dev branch Submitting technical documents is as follows:\n1 2 3 git remote add origin https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/xxx.git #Add remote library, change it to your own remote library git fetch origin -a #Get all branches of remote library touch docs/technical.md #Record technical documents in markdown format Open the docs/technical.md file and complete the writing of the technical document. After that, do the following:\n1 2 3 4 5 6 git add docs/technical.md #Add the technical document to the staging area git commit -m \u0026#34;[docs]Add technical document\u0026#34; git push origin master git checkout -b dev #Create and switch to the dev branch git push origin dev Internal team collaboration When collaborating internally, Developer #1, Developer #2, and Tester are all in the same team. They are all members of the project and can directly submit code to the same repository;\nNext, two application scenarios are explained according to the GitLab Flow workflow.\nDevelop new features Development and testing of new features cannot be modified on one branch, but a new branch should be created, named feat_xxx to represent the development of xxx feature.\nNext, Developer #1 raises an issue and creates two new branches in the issue named feat_xxx and test_xxx, which are used by Developer #2 to submit feature code to the feat_xxx branch and testers to submit test case code to the test_xxx branch.\nAmong them, the feat_xxx branch is based on the latest dev branch, and the test_xxx branch is based on the feat_xxx branch. The workflow is as follows:\nDeveloper #1 submits an issue according to the document of the dev branch. Developer #1 creates a new branch feat_xxx based on the dev branch in the issue and notifies Developer #2 to develop the function\nDeveloper #2 obtains and checks out to the feat_xxx branch\nIf the feat_xxx branch does not exist, you need to create and switch to a new branch. Execute the following instructions:\n1 2 git fetch origin -a #Get all branches of the remote library git checkout -b feat_xxx origin/feat_xxx #Create a feat_xxx branch locally based on the remote feat_xxx branch and switch to it If feat_xxx branch already exists, execute the following command:\n1 2 git checkout feat_xxx #No need for the -base parameter, because the local feat_xxx branch already exists git pull origin feat_xxx:feat_xxx #Pull the remote feat_xxx branch to the local feat_xxx branch Developer #2 develops on feat_xxx and pushes it to the remote library after development is completed 1 2 3 git add \u0026lt;files\u0026gt; git commit -m \u0026#34;[feat] Add xxx function\u0026#34; #\u0026#34;[feat]\u0026#34; indicates that this is a new function git push origin feat_xxx Note: If the modification of feat_xxx is a new function, the comment of the commit record should be prefixed with \u0026ldquo;[feat]\u0026rdquo;.\nDeveloper #2 has not submitted an MR before, so he creates an MR request to merge feat_xxx into the dev branch, and the Issue needs to be associated with the MR. After the Developer #2 completes the new function, he needs to associate the MR in the Issue, through the !\u0026lt;MR_number\u0026gt; method. Assuming that the serial number of the MR is 9, the comment See merge request !9 should be added to the Issue;\nAlso, add a comment in Merge Request to indicate which Issue this corresponds to, through the #\u0026lt;Issue_number method. Assuming that the Issue corresponding to the MR is 5, the comment See issue #5 should be added.\nDeveloper #1 reviews the code. If the review fails, he/she will state the improvement suggestions in the MR and return to step (3) The comment of the submission record here should still be [perf] Improve xxx, where \u0026ldquo;[perf]\u0026rdquo; is the improvement made for xxx\nIf the review passes, Developer #1 will create a sub-item Issue in the Issue, create a test_xxx branch based on the feat_xxx branch, and assign the Issue to the tester Note: Developer #1 should not pass the MR after the review passes. The tester needs to submit the test case and pass the test. Then the tester needs to submit an MR request to merge the test_xxx branch into the feat_xxx branch. Only then can Developer #1 confirm the MR and feat_xxx will be deleted;\nThe tester pulls the test branch code, writes the test case and submits it to the test_xxx branch 1 2 3 4 5 6 7 #If the test_xxx branch already exists, execute the following command git checkout test_xxx #Execute for the first pull: git checkout -b test_xxx origin/test_xxx touch test/test_xxx #Write a test script #Write a script for test cases written in other languages git add test/test_xxx git commit -m \u0026#34;[test] Test xxx function\u0026#34; #Commit the \u0026#34;[test]\u0026#34; annotation of the record, indicating that it has modified the test code git push origin test_xxx Whether the test case is correct or not, the test case program should be submitted, and the submission record prefix should be \u0026ldquo;[test]\u0026rdquo;, indicating that this is a test case.\nIf the tester has not proposed an MR before, then create an MR request to merge test_xxx into the feat_xxx branch. The Issue and the corresponding MR need to be associated\nDeveloper #2 reviews the tester\u0026rsquo;s MR. If it does not pass, return to step (10). Otherwise, it will be submitted to Developer #1 for review. If Developer #1 passes the review, the merge is allowed\nDeveloper #1 allows the merge, which will delete the test_xxx branch, and then the MR will be closed. Developer #1 is also required to mark the test issue as completed\nDeveloper #1 and Developer #2 update feat_xxx. They can first test locally. If there are problems, return to step (3) 1 2 3 git fetch origin feat_xxx git checkout feat_xxx #Switch to the local branch to be merged git merge origin/feat_xxx #Merge the remote library into the current branch If all test cases pass, Developer #1 confirms that the MR has passed and merges feat_xxx into the dev branch. Dealing with integration issues When testing a function alone, everything works fine, but there is a problem when integrating it. The following example is used to introduce it.\nAssume that the requirements have not changed significantly, the original function feat_xxx1 (no problem), add a new function feat_xxx2, and there is no problem when testing feat_xxx2 alone, but a problem occurs after the integration test. The tester needs to raise an issue first, and other members should actively discuss and locate the problem;\nHere, there is no need to go back to the feat_xxx2 branch to fix the problem (maybe the problem of feat_xxx1 was not exposed in the previous integration test), but to create a new branch on the integrated dev branch to fix the integration problem.\nThe specific workflow is as follows:\nThe tester tests based on the dev branch, and raises an issue if a problem is found, explaining the phenomenon of the problem and what operations were performed If the problem occurs in a certain test case, the test case program should be submitted and then an MR should be submitted to request to merge test_dev into the dev branch, and then the MR and the corresponding issue should be associated in the issue\nIf other members discuss and confirm that there is a problem, after Developer 1 and Developer 2 pass the tester\u0026rsquo;s MR, Developer 1 confirms the merge, and the test_dev branch will be deleted\nNote:\nFeat_xxx3 and feat_xxx4 may be developed at the same time. Each function is fine when tested separately, but problems occur after integration. They are merged into the dev branch without conflict. The tester should create two new branches locally for these two integrations. For the commits of feat_xxx3 merged into dev, create a test_dev branch, and for the commits of feat_xxx4 merged into dev, create a test_dev1 branch. Branch naming is analogous.\nIf you merge into the dev branch multiple times in a row, including adding new functions and fixing problems with old functions, you should create a tag through the following command:\n1 2 3 git checkout dev git tag release-x.x.x #Switch to the dev branch and create the current branch as a release version git push origin release-x.x.x #Push the version to the remote Generally, the tester tests the code on the branch of release-x.x.x. If there is a problem, create a test-release-x.x.x branch locally for testing. The operation is as follows:\n1 2 3 4 5 git fetch origin -a git checkout -b test-release-x.x.x origin/release-x.x.x #Create a test branch based on the remote release version #Test, if there is a problem that must be found, submit the corresponding test case. The following operations are required git commit -m \u0026#34;[test] Test release version x.x.x\u0026#34; git push origin test-release-x.x.x After locating the problem (assuming that the problem occurs in feat_xxx2 developed by developer 2), developer 1 creates a fix_xxx2 branch in the Issue based on the problematic dev branch and assigns it to developer 2\nDeveloper 2 needs to modify and submit the code on fix_xxx2\nThe submission record here is annotated as [fix] Fix xxx problem\nDeveloper 2 performs the same operation as the tester. If the problem still occurs, return to step (3)\nDeveloper 2 submits a MR request to merge fix_xxx2 into the dev branch, and associates the MR with the corresponding fix issue\nTester 2 pulls fix_xxx2 for testing. If there is no problem, it passes, but it will not be merged into the dev branch\nDeveloper 1 observes the bug fix, and finally passes the merge, and the fix_xxx2 branch will be deleted\nCross-team development workflow After developer 3 joins, the code submitted by developer 3 may affect existing functions due to lack of precautions. Therefore, developer 3 should fork the upstream repository for development, and other members should continue to develop in the original way.\nDeveloper 3 should do the following:\n1 2 3 git clone https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/repo-xxx.git #Clone the forked repository to the local cd repo-xxx git remote add upstream https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/repo-xxx.git #Add the forked repository as the upstream repository Assuming that the project is urgent and the function that should have been implemented by Developer 2 is handed over to Developer 3 for development, Developer 1 should raise an Issue in the upstream repository and create a feat_xxx branch based on the dev branch. When Developer 3 receives the notification, he should do the following:\n1 2 git fetch upstream feat_xxx #Get the feat_xxx branch of the upstream repository git checkout -b feat_xxx upstream/feat_xxx The subsequent operations are similar to the development workflow within the team.\nNote:\nIf developer 3 needs to submit an MR, he should create an MR in his forked repository;\nIf developer 3 receives an assignment, he should pull the corresponding branch from the upstream repository upstream to the local, and then modify and submit the code on the branch\nDeveloper 3 cannot push directly to the upstream repository, but should push to the forked repository, and then create an MR request to merge it into the corresponding branch of the upstream repository. The MR needs to be associated with the corresponding issue in the upstream repository.\nSupplement The remote library branch is deleted after MR, how to delete the remote library fetched locally After developer 1 confirms MR, the remote library\u0026rsquo;s feat_xxx branch is deleted, but the local feat_xxx still exists\n1 2 3 4 git fetch -p #-p is the abbreviation of --prune git checkout dev #If you are currently on the feat_xxx branch git branch -d feat_xxx #Delete the local feat_xxx branch git branch -D feat_xxx #Note: This means that the local branch has not been merged and will be forcibly deleted There is a big problem with a certain release version. How to delete the deleted remote library tag stored locally 1 git fetch -P #-P is the abbreviation of --prune-tags In cross-team collaboration, after the upstream warehouse MR, how to synchronize the forked remote library with its upstream warehouse Assuming that your MR requests to merge fix_xxx into the dev branch of the upstream warehouse, after developer 1 confirms the merge, the operation is as follows\n1 2 3 4 5 6 7 8 git fetch upstream -a #Get changes in the upstream warehouse git merge upstream/dev dev #Synchronize the upstream warehouse to the local dev branch #or git pull upstream dev:dev #Replace the above 2 lines of instructions git push origin dev #Synchronize local changes to the fork warehouse git checkout dev #If you are currently in the fix_xxx branch git branch -d fix_xxx #Delete the local fix_xxx branch git fetch -p #Delete the deleted fix_xxx branch stored locally How to name a new branch For example, to add a new feature Add query temperature function, you should create a new branch named feat_query_temp in the current branch (usually dev branch) (where feat is the abbreviation of feature);\nThe naming format of the new branch is as follows:\n1 type_subject Submission type (type): including feat (new feature), fix (fix problem), doc (document change), refactor (code refactoring, not new feature, not bug fix), test (add or modify test), chore (other submissions that do not modify source code or test cases), style (code format, does not affect code operation);\nShort description (subject): Use underscores _ to separate words, and be concise and clear.\nThe naming rule example is as follows:\n1 2 3 4 feat_support_eth #Support network port refactor_cmd_resp #Refactor command reply prompt information style_format_code #Format source code test_cmd_resp #Test command reply prompt information How to write commit comments Commit comments should be as concise and clear as possible, and directly reflect the changes in the submitted code;\nNew features and bug fixes should also be submitted in two batches, and other types of submissions should be submitted in the same way;\nYou can submit to the local library through the git commit -m \u0026lt;message\u0026gt; command, where the description of \u0026lt;message\u0026gt; is as follows:\n1 Format: [type]msg Where type values ​​and their meanings are as follows:\ntype Meaning Example feat New feature (feature) [feat] Add health check fix Fix bug (fix bug) [fix] Fix health check relocation problem doc Documentation changes (documentation) [doc] Improve technical documentation style Code formatting [style] Format non-generated source code refactor Refactor code [refactor] Refactor command reply prompt test Add or modify tests [test] Test health check chore Commit without modifying source code or test files [chore] Improve .gitignore perf Changes to improve performance [perf] Improve sliding average performance ci Changes related to continuous integration [ci] Automatically generate and publish hex and bin files build Changes to build system or external dependencies [build] Improve CMakelists.xt configuration revert Undo previous submission [revert] Rollback scheduled tasks How to automatically perform specific operations for each submission If you need to format the code before each submission, you should normally perform specific operations actively, but you can configure .git/hooks/pre-commit to perform the desired operations. The example is as follows:\n1 2 3 4 5 6 git clone https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/repo_xxx.git cd repo_xxx.git touch .git/hooks/pre-commit #Create a pre_commit text file in the .git/hooks directory #Edit pre-commit content chmod +x .git/hooks/pre_commit #Modify the pre-commit attribute to be executable The content of pre-commit is as follows:\n1 2 3 4 5 6 7 8 9 10 #!/bin/sh # Find all C source files and header files files=$(git diff --cached --name-only --diff-filter=ACM | grep -E \u0026#39;\\.(c|h)$\u0026#39;) # If there are no files to format, exit [ -z \u0026#34;$files\u0026#34; ] \u0026amp;\u0026amp; exit 0 # Run clang-format on each file with the specified .clang-format file echo \u0026#34;$files\u0026#34; | xargs clang-format -i --style=file # Add the formatted files back to the staging area echo \u0026#34;$files\u0026#34; | xargs git add exit 0 After the above configuration, each time git commit is executed, it will filter \u0026ldquo;.c\u0026rdquo; and \u0026ldquo;.h\u0026rdquo; files in the modified files, and then format the files through clang-format according to the \u0026ldquo;.clang-format\u0026rdquo; configuration file in the root directory.\nReference https://www.cnblogs.com/xiaoqi/p/gitlab-flow.html\nhttps://www.atlassian.com/git/tutorials\nhttps://git-scm.com/book/\nhttps://docs.github.com/zh/get-started/start-your-journey/about-github-and-git\n","date":"2024-10-06T11:34:59+08:00","image":"https://adja.com.cn/p/teamwork-using-git/cover_hu_68aa3635992a5706.jpg","permalink":"https://adja.com.cn/en/p/teamwork-using-git/","title":"Teamwork Using Git"},{"content":"Use DDNS To Access Intranet Devices Sometimes I need to access my home NAS when I go out. Since it is increasingly challenging to apply for a public IPv4 in China, and the official QuickConnect service of Synology is also very slow. After referring to relevant tutorials, I decided to resolve the domain name to public IPv6 through DDNS and access the intranet devices directly through the domain name.\nBased on the previous experiment of cracking the optical modem to get the superuser privileges to modify the routing mode, I connected the router to the optical modem. Then let the router dial and turn on IPv6, and after assigning the public network IPv6, I started the DDNS configuration process.\nThrough Synology\u0026rsquo;s DNS service Open the Control Panel, click External Access, select DDNS, then click Add, and select Synology as the service provider. Then customize the configuration below.\nIf you need https access, check \u0026ldquo;Get a certificate from Let\u0026rsquo;s Encrypt\u0026rdquo; and click OK.\nUsing a DNS service from another provider The following only takes Tencent Cloud\u0026rsquo;s DNS service as an example. You need to apply for a domain name on Tencent Cloud\u0026rsquo;s official website in advance.\nUsing the ddns-go image To perform dynamic domain name resolution, you need your own NAS device to query the local IP address regularly, and then call the interface to update the domain name resolution field to implement DDNS.\nSo you can\u0026rsquo;t change the method. There are many methods on the Internet. Here I provide a method to use Docker to update DDNS.\nSearch for Docker in the package center and install Docker. The steps are omitted.\nOpen Docker, select \u0026ldquo;Registry\u0026rdquo;, search for ddns, and install the first \u0026ldquo;ddns-go\u0026rdquo;\nAfter the installation is complete, open the image, select ddns-go, and click Start.\nClick Advanced Settings-\u0026gt;Storage-\u0026gt;Add Folder.\nModify the mount path, my configuration is as follows:\nClick Network-\u0026gt;Check Host Network-\u0026gt;Apply.\nClick Next, click Finish.\nConfiguring DDNS Open http://[nas ip corresponding to the domain name]:9876/\nConfigure DNS service provider, select Tencent Cloud, enter ID and Token, Note that the ID and Token here correspond to \u0026ldquo;DNSPod Token\u0026rdquo;, not \u0026ldquo;Tencent Cloud API Key\u0026rdquo;, the link is https: //console.dnspod.cn/account/token/token\nOnly enable ipv6, my configuration is as follows:\nBefore clicking \u0026ldquo;Save\u0026rdquo;, you need to configure the domain name resolution and add an AAAA type (indicating an IPv6 address) record. Fill it out and it will automatically update. My configuration is as follows:\nAfter the configuration is completed, click Save, and the latest history records will appear on the right.\nFinally, you can test it through domain name + port.\nAdditional In the summer of 2022, after the installation was completed, I asked my classmates to help test the speed of different prefecture-level cities in Jiangsu. The speed was still quite fast.\nAfter graduation, I went to other provinces. After finding my first job. I thought about NAS again and tried to continue using it, but found that the same method did not work at all, mainly because the network infrastructure varies greatly between provinces.\nIf you are in a province where IPv6 has not been promoted, it is recommended to Avoid tossing. In addition, due to the proliferation of PCDN in the past few years, operators will check whether users have built PCDN based on the upstream speed of bandwidth. If DDNS is used maliciously, it may cause broadband to be blocked.\n2022-06-19 Record\n2023-07-07 Update\n","date":"2024-07-06T16:08:49+08:00","image":"https://adja.com.cn/p/use-ddns-to-access-intranet-devices/cover_hu_b5ef505a63f32487.jpg","permalink":"https://adja.com.cn/en/p/use-ddns-to-access-intranet-devices/","title":"Use DDNS To Access Intranet Devices"},{"content":"Development Environment Management Tools When developing, multiple development environments are often used. You may have used tools like miniconda, nvm, and gvm, which are used to manage versions of python, nodejs, and go respectively. in addition, there are package management tools such as maven.\nIf you use a new programming language or package management tool, it is troublesome to install the corresponding version management tool. Next, we will introduce three development environment management tools: asdf, mise, and vfox.\nComparison of asdf, mise and vfox All three are tools for managing development environments, and all provide unified command line instructions. Their functions can be expanded by installing plugins.\nasdf Asdf was born earlier, and its plug-in ecosystem is more complete. It is mainly developed using shell scripts and can be well adapted to Linux and Mac. When it comes to support for Windows, someone raised a similar issue to the official, but no version supporting Win was provided later.\nOf course, if you must use asdf on the Win platform, you can install and use it in wsl, but considering that the speed of wsl is far inferior to that of the native exe format program, and the shell itself is interpreted and executed, the speed is even slower. Therefore, except for the Win platform, other platforms recommend using asdf.\nmise The original name of this tool is rtx. Since the original name is easily confused with the name of Nvidia\u0026rsquo;s graphics card, it was later renamed mise. It is developed in the rust programming language.\nBecause the backend uses asdf, it also inherits the shortcomings of asdf and also has poor support for the Win platform.\nvfox vfox is developed in the go programming language. Compared with the other two tools, it is finally compiled into an executable file. Therefore, it is much faster and has a smaller size, and it also provides native support for the Win platform.\nThe only drawback is that most users of this type of tool may use Linux and Mac systems, and vfox has fewer contributors and its functions need to be improved, but it should exceed the first two in the future.\nSummary Comparing the characteristics of the three, I prefer to use vfox to manage the development environment. Despite this, I still use language-specific version management tools such as miniconda in daily life.\nEven if you have learned a lot of programming languages, most people mainly use 3 or less programming languages in daily life. Solving the installation and use of three tools is more difficult than solving the bug of one tool. The former takes less time and does not require searching for solutions and then raising an issue.\nIn addition, I have recently found that the configuration of the environment is becoming simpler while tossing automation tools. Dev Container is a blessing for software development. Perhaps in the future, developers of any platform will not have to pay attention to the installation and configuration of the environment. I look forward to the arrival of this day.\n2024-06-119 First update\n","date":"2024-06-19T07:34:46+08:00","image":"https://adja.com.cn/p/dev-environment-management-tools/cover_hu_d836b88666e47319.jpg","permalink":"https://adja.com.cn/en/p/dev-environment-management-tools/","title":"Development Environment Management Tools"},{"content":"Blog Migration It has gone about 5 months since I wrote blogs last time. During this time, I spent most of my time at work. Even if I\u0026rsquo;m free, I didn\u0026rsquo;t spend much time to make up for the lack of knowledge. It wasn\u0026rsquo;t until last month, around mid-April, that I gradually wanted to get rid of this state. So I stated from the areas that interests me. Next, let me review what happened in the past months.\nCause Since I graduated and worked nearly half a year ago, in addition to daily entertainment, I often browse GitHub, go out for dinner with friends, or play \u0026lsquo;World of Warcraft\u0026rsquo; online with classmates, etc. But I always felt like something was missing. After they started working and going to school, they had less and less time for dinner and entertainment together.\nAlthough I can study new things in daily work, I feel still lacking. Later I realized that It was probably because I didn\u0026rsquo;t take enough action and was consumed by the anxiety on the Internet. I gradually realized that if I continued like this, I would never live up to my expectations.\nMigration I have been considering migrating my blog since the beginning of May. It\u0026rsquo;s necessary to consider the following aspects when migrating my blog:\nLower learning cost Reusable Indirect or direct access to areas of interest Framework stability After comprehensive consideration, I finally chose the hugo framework. On the one hand, hugo is widely used. In addition, I may use Golang when exploring network knowledge in the future. It just so happened that hugo was developed using the Golang.\nNext, I need to choose a nice theme. However, Hugo has less reference documents than Hexo. So at first, I considered hugo-theme-bootstrap Because its Chinese documents is well written and supports both blog and document layouts. However, there are not many participants, and the author may not maintain it for a long time, so I didn\u0026rsquo;t adopt it in the end. Later I adopted hugo-theme-stack, it has almost no third-party dependencies, and the Chinese document is relatively complete.\nAfter improving the overall layout and some details, I spent half a day thinking about Github Actions. I had used Jenkins to build before, but this time I was struck on the authentication of the deployment public key. Finally I solved it.\nPlanning I should reflect on the fact that I didn\u0026rsquo;t stick to most of the plans I made in the past (such as improving English, learning FPGA and circuit knowledge, exploring computer networks, etc.).\nAmong them, I really couldn\u0026rsquo;t stick to improving English, so I simply learned English by supporting multilingual articles; As for computer networks, I often debug LWIP at work, and often toss around on cloud servers and local nas in my life. I may participate in related open source projects in the future; When it comes to hardware-related things, I feel a headache, but since I will use it in my future work, I plan to learn the development board I bought; In addition, I also need to understand the new rust language (communicate with colleagues), learn Linux development, learn 408\u0026hellip; It\u0026rsquo;s such a headache that there are too many things I want to do.\nCombining interests and work, I need to improve my blog, explore computer networks, learn FPGA and circuits, and find time to understand the rust language.\n2024-06-17 First update\n","date":"2024-06-17T00:46:21+08:00","image":"https://adja.com.cn/p/blog-migration/cover_hu_d64c50090b23f678.jpg","permalink":"https://adja.com.cn/en/p/blog-migration/","title":"Blog Migration"},{"content":"Two-month Life Experience In Hefei I came to Hefei at the end of July after graduation. It has been almost two months now. Let me summarize my recent life experience.\nWork and rest schedule Comparing the schedule at home and at school, I may be used to being alone, but it also makes me more focused. In addition to working 996, I spend two or three hours every day studying future work, research or professional knowledge that I am interested in.\nThe room is a single room rented for 750 per month, and the bathroom is shared. Considering that sometimes I go home very late at night, or the bathroom is occupied, if I need to do laundry, I must go home as early as possible (try to get home before 9:20 at the latest) or go to do laundry an hour earlier in the morning (before 7:30 in the morning) to avoid disturbing other tenants\u0026rsquo; sleep.\nSince it only takes 20 minutes to walk to the workplace, I leave at around 8:35 every morning and arrive at my workstation 10 minutes earlier (the morning work starts at 9 o\u0026rsquo;clock).\nWhen it comes to working hours (although the work here refers to training, or in some schools as internship), it is relatively dull. Since I already have a solid foundation, I will choose to take time to learn more basic computer knowledge, or solve problems encountered in integrating knowledge, or make up for the lack of professional knowledge.\nThe morning work starts at 9:00 and lasts until 12:00 noon. The 2 hours at noon include half an hour for lunch, half an hour for free use (for watching Bilibili or solving problems), and nearly an hour for sleep, etc.\nThe afternoon work starts at 2pm and lasts until 6 o\u0026rsquo;clock in the afternoon, followed by an hour of free time to eat dinner or do something else.\nI work until 9pm, and the workday is over. When I go home, I pack up my computer and go home.\nI return home and turn on my computer to continue yesterday’s study tasks. Sometimes I am too tired to do anything, so I lie on the table and take a nap for an hour, or I really don’t want to study (for example, I want to watch some movies, or find some interesting novels, or my beard is too long and hard and needs to be dealt with). When I don’t want to study, I will indulge myself for a night and continue the unfinished task the next day.\nLife experience When I was studying, I usually stayed at home during holidays because my home was in the countryside. There were no entertainment venues, stalls, restaurants, or supermarkets around, which made it very troublesome to go out, eat, and shop.\nAfter graduation, I rented a house in Hefei. Although the cost of living increased, and it cost about 1,650 yuan a month (750 yuan for rent + 900 yuan for food), it was extremely convenient for receiving express delivery, shopping, eating, and traveling.\nHowever, big cities also have some disadvantages (maybe not for others). There are many bridges and subways here, and various codes are required for travel, which is very unfriendly for rural people who come to big cities for the first time. In addition, the inaccurate positioning of mobile phone navigation is a headache.\nDuring the rental period, there was a bad thing of toilet blockage. It was probably because the tenants were used to throwing toilet paper directly into the toilet after using it. Although the problem was solved in about a week, it was really uncomfortable to use the bathroom during this period.\nWork experience If you love computers, working 996 hours a day is actually nothing. You can still improve a lot in the process and learn a lot of useful things.\nIn the past two months of work and study, I always felt that something was missing. Later, I gradually found that I was missing the passion I had when I first entered university. Although I get along well with the people around me and often help others solve their doubts, there is always a sense of distance between us.\nDespite this, I still hope that I can maintain myself and keep improving.\nFuture plans Considering that I plan to work on drivers or low-level development in the future, I will study kernels and assembly languages under other architectures in my spare time.\nThe two months of living in Hefei, although generally much better than at home, still do not meet my expectations. Maybe it is because my current life does not meet my expectations, or I cannot meet people who are good enough or like-minded. I will definitely take the postgraduate entrance examination in the next two to three years. However, before that, I need to lay a solid foundation (mainly operating systems and computer composition principles) and find the direction I want to study.\nIn addition, since Hefei has a complete range of industries and is developing high-tech technologies (nuclear fusion, quantum chips), the future is bright, both now and in the future. If I work in the future, I will most likely work in Hefei, which can be regarded as a contribution to my hometown.\n2023-09-23 Updated\n","date":"2023-09-23T14:05:34+08:00","image":"https://adja.com.cn/p/two-month-life-experience-in-hefei/cover_hu_7ea39ed252ba7dd1.jpg","permalink":"https://adja.com.cn/en/p/two-month-life-experience-in-hefei/","title":"Two-month Life Experience In Hefei"},{"content":"Automated Build Via Jenkins Continuing on from the previous experiment, we will implement a one-click deployment project through Jenkins.\nProject Overview The project is a frontend and backend separation project. The backend is a multimodule project using SpringBoot, and its structure is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 +---backend # Backend | +---src | \\---target +---frontend # Frontend | +---dist | \\---src +---others # Other Backend Modules | +---mqtt | +---src | \\---target +---data # Database Config | +---conf | +---init | \\---sql +---conf # Config | +---emqx | \\---nginx +---dockerfile +---shell # Scripts To Help Build Images \\---docker-compose.yml Problems For convenience, the automated build process is done in a Jenkins container. With Docker, we don\u0026rsquo;t have to spend a lot of time configuring the environment. Next, let me introduce the problems encountered.\nCommends not found Through the logs, I observed that the npm command could not be found. Because I manged the Node environment through nvm and didn\u0026rsquo;t configure the PATH variable, npm command always failed to execute.\nFinally I mounted the nvm installation directory and configuration to the Jenkins container. When the container is started, first make the configuration file in the /etc/profile.d directory take effect, and then switch the node environment. The Pipeline I wrote is as follows.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 stage(\u0026#39;build-frontend\u0026#39;) { steps { dir(\u0026#34;./frontend\u0026#34;) { sh \u0026#39;\u0026#39;\u0026#39; source /etc/profile.d/nvm.sh nvm use 16.15.0 npm cache clean –force npm cache verify if [ -f dist ]; then rm dist -rf; fi; pnpm config get registry pnpm config set registry https://registry.npmmirror.com/ pnpm install pnpm run build:prod \u0026#39;\u0026#39;\u0026#39; } } } Note: Errors such as commands not found can be solved by mounting its installation directory and making the configuration effective.\nHow to deploy remotely via ssh After configuring the private key on the global credentials, it is best to deploy remotely in Pipeline through a plugin (SSH Pipeline Steps). You can refer to my configuration.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 steps { withCredentials(bindings: [ \\ sshUserPrivateKey(credentialsId: \u0026#39;private-key\u0026#39;, keyFileVariable: \u0026#39;primaryKeyVar\u0026#39;, passphraseVariable: \u0026#39;pwdVar\u0026#39;, usernameVariable: \u0026#39;userVar\u0026#39;)]) { script { def remote = [:] remote.name = \u0026#39;192.168.137.2\u0026#39; remote.host = \u0026#39;192.168.137.2\u0026#39; remote.user = userVar remote.identityFile = primaryKeyVar remote.allowAnyHosts = true stage(\u0026#39;Remote SSH\u0026#39;) { sshCommand remote: remote, command: \u0026#34;mkdir -p ${REMOTE_WORKDIR}/frontend\u0026#34; // Frontend Packaging File sshPut remote: remote, from: \u0026#34;./frontend/dist\u0026#34;, into: \u0026#34;${REMOTE_WORKDIR}/frontend\u0026#34; // Show All Files Transferred sshCommand remote: remote, command: \u0026#34;ls -lrt ${REMOTE_WORKDIR}/**\u0026#34; } } } } How to control the startup order of services When writing docker-compose.yml, if you need to control the startup order, the depends_on field alone is not enough. It only controls the startup order, but doesn\u0026rsquo;t guarantee that the next service will be started only after the service is successfully started.\nI referred to many articles and found a solution. By mounting wait-for-it.sh, write a script to replace the container\u0026rsquo;s entrypoint. If you have any question, you can also refer to [this article] (https://www.cnblogs.com/wang_yb/p/9400291.html).\nI downloaded the script called *wait-for-it from [https: //github.com/vishnubob/wait-for-it](https: //github.com/vishnubob/wait-for-it). I renamed it entrypoint.sh and put it in the shell directory. Below is part of the docker-compose configuration.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 service: backend: build: context: . dockerfile: dockerfile/backend-Dockerfile image: backend_app container_name: prod-backend-app ports: - \u0026#34;13245:13245\u0026#34; environment: TZ: Asia/Shanghai PORT: 13245 PROFILE: prod volumes: - ./shell/entrypoint.sh:/entrypoint.sh depends_on: - emq - influx The Dockerfile of the service called backend is renamed backend-Dockerfile and is placed in the dockerfile directory. Since the backend service relies on the mysql and redis services, the content of its Dockerfile is as follows:\n1 2 3 4 5 FROM openjdk:8-jdk ADD backend/target/*.jar /app.jar CMD bash /entrypoint.sh mysqldb:3306 -t 30 -- echo \u0026#34;mysql started\u0026#34; \\ \u0026amp;\u0026amp; bash /entrypoint.sh redisdb:6379 -t 20 -- echo \u0026#34;redisdb started\u0026#34; \\ \u0026amp;\u0026amp; java -jar -Dfile.encoding=utf-8 -Dserver.port=${PORT} -Dspring.profiles.active=${PROFILE} /app.jar How to configure Emqx First of all, the version of Emqx is 4.4.2.\nI referred to the official document and configured the container through environment variables. The emq_web_hook plugins is effective but the emq_http_auth plugin is always ineffective. I tried various methods but failed. At last, solved it by mounting its configuration file.\nYou can refer to my docker-compose configuration:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 service: emq: user: root restart: always container_name: prod-emqx image: emqx/emqx:4.4.2 ports: - \u0026#34;18083:18083\u0026#34; - \u0026#34;1883:1883\u0026#34; - \u0026#34;8083:8083\u0026#34; - \u0026#34;8084:8084\u0026#34; - \u0026#34;8883:8883\u0026#34; volumes: - /etc/localtime:/etc/localtime - /root/docker/emqx/log:/opt/emqx/log - ./conf/emqx/emqx_auth_http.conf:/opt/emqx/etc/plugins/emqx_auth_http.conf - ./conf/emqx/emqx_web_hook.conf:/opt/emqx/etc/plugins/emqx_web_hook.conf environment: EMQX_ALLOW_ANONYMOUS: false # allow_anonymous EMQX_LOADED_PLUGINS: \u0026#34;emqx_management,emqx_auth_http,emqx_dashboard,emqx_web_hook\u0026#34; EMQX_DASHBOARD__DEFAULT_USER__LOGIN: root EMQX_DASHBOARD__DEFAULT_USER__PASSWORD: 12345 networks: app_net: ipv4_address: 172.31.0.10 depends_on: - auth links: - auth The frontend can\u0026rsquo;t access the backend container\u0026rsquo;s interface Many articles introduce the use of nginx as the base image to build the front-end image.\nI referred this article and wrote the nginx configuration file, the example is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 server { listen 13246; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } #Location配置 location /api/ { rewrite /api/(.*) /$1 break; proxy_pass http://backend:13245; } } Since I had not learned nginx in depth, I encountered various problems. After repeated attempts, I finally achieved my expectations.\nAdditional Notes The project is based on Vue3 and SpringBoot, and uses Jenkins container for automated construction and deployment. For convenience and space saving, the best way is to install common tool software on the host machine and then mount it into the container.\nNext I will add some installation dependencies\nInstall Docker 1 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun Install jdk8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rm /tmp/jdk*.tar.gz -f wget https://repo.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz -P /tmp ls -lht /tmp/ | grep jdk mkdir -p /usr/local/java/ tar -zxf /tmp/jdk-8u202-linux-x64.tar.gz -C /usr/local/java/ \u0026amp;\u0026amp; ls /usr/local/java/ -l # Add environment jdk1.8 environment variables cat \u0026gt; /etc/profile.d/java.sh \u0026lt;\u0026lt;EOF export JAVA_HOME=/usr/local/java/jdk1.8.0_202 export JRE_HOME=\\${JAVA_HOME}/jre export CLASSPATH=.:\\${JAVA_HOME}/lib:\\${JRE_HOME}/lib export PATH=\\${JAVA_HOME}/bin:\\$PATH EOF source /etc/profile.d/java.sh ln -s ${JAVA_HOME}/bin/java /usr/bin/java java -version Install Maven 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 maven_version=3.9.0 rm /tmp/*maven*.tar.gz -rf #wget https://dlcdn.apache.org/maven/maven-3/3.9.0/binaries/apache-maven-3.9.0-bin.tar.gz -P /tmp wget https://mirrors.aliyun.com/apache/maven/maven-3/3.9.0/binaries/apache-maven-3.9.0-bin.tar.gz -P /tmp ls -lht /tmp/ | grep maven mkdir -p /usr/local/maven/ tar -zxf /tmp/apache-maven-*.tar.gz -C /usr/local/maven/ \u0026amp;\u0026amp; ls /usr/local/maven/ -l # Add Maven environment variables cat \u0026gt; /etc/profile.d/maven.sh \u0026lt;\u0026lt; EOF export MAVEN_VERSION=\u0026#34;${maven_version}\u0026#34; export M2_HOME=/usr/local/maven/apache-maven-\\${MAVEN_VERSION} export MAVEN_HOME=/usr/local/maven/apache-maven-3.9.0 export PATH=\\${MAVEN_HOME}/bin:\\${PATH} EOF chmod +x /etc/profile.d/maven.sh source /etc/profile.d/maven.sh mvn -version Install nvm 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 nvm_version=0.39.3 rm /tmp/v${nvm_version}.tar.gz -rf wget https://github.com/nvm-sh/nvm/archive/refs/tags/v${nvm_version}.tar.gz -P /tmp ls -lht /tmp/ | grep \u0026#34;v${nvm_version}.tar.gz\u0026#34; mkdir -p /usr/local/nvm/ tar -zxf /tmp/v${nvm_version}.tar.gz -C /usr/local/nvm/ \u0026amp;\u0026amp; ls /usr/local/nvm/ -l # Add nvm environment variables cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/profile.d/nvm.sh export NVM_VERSION=\u0026#34;${nvm_version}\u0026#34; export NVM_DIR=\u0026#34;/usr/local/nvm/nvm-\\${NVM_VERSION}\u0026#34; [ -s \u0026#34;\\$NVM_DIR/nvm.sh\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;\\$NVM_DIR/nvm.sh\u0026#34; # This loads nvm [ -s \u0026#34;\\$NVM_DIR/bash_completion\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;\\$NVM_DIR/bash_completion\u0026#34; EOF chmod +x /etc/profile.d/nvm.sh source /etc/profile.d/nvm.sh nvm version Install docker-compose It is recommended to download docker-compose from github official website, some mirror website packages are too old.\n1 2 3 curl -L https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose docker-compose -v Summary By applying the newly learned Jenkins automation technology to the project, time can be greatly saved. Operation and maintenance do not have to repeatedly deploy manually, and testing becomes a part of development. Only test scripts need to be written. Each time the developer submits code, the test scripts will be automatically executed and then deployed to the remote via ssh. From the traditional stage-by-stage development, where a stage cannot be skipped directly, development can now be quickly tested and put into production to get feedback, doubling efficiency. Perhaps this is why the CI/CD concept and tools are popular.\nReferences https://github.com/vishnubob/wait-for-it\nhttps://www.cnblogs.com/wang_yb/p/9400291.html\nhttps://juejin.cn/post/6844903837774397447\nhttps://juejin.cn/post/7095729903684829191\n2023-02-16 First Update\n2023-02-26 Add Dependent Installation configuration\n2024-07-06 Support English\n","date":"2023-02-16T15:10:34+08:00","image":"https://adja.com.cn/p/automated-build-via-jenkins/cover_hu_ef3c10312f6a2c51.jpg","permalink":"https://adja.com.cn/en/p/automated-build-via-jenkins/","title":"Automated Build Via Jenkins"},{"content":"Crack The Optical Modem Superuser Password First of all, I want to emphasize that the optical modem model is HS8545M5, and the software version is V5R020C00S200.\nSince the optical modem needs to be in routing mode by default when it is shipped, I need to change it to bridge mode. However, the user on the back of the optical modem does not have the permission to modify it, so I need to get superuser permissions.\nEnable Telnet on the optical modem The telnet service is not enabled on the optical modem, so we need a tool to crack it. The download link of the cracking tool is at the end.\nFirst download the cracking tool, then unplug the optical fiber, restart the optical modem, connect the computer to the optical modem via the broadband cable, and open the ONT maintenance enabling tool.\nSelect maintenance enabling, click refresh, and then start.\nWhen the \u0026ldquo;current total number of successes\u0026rdquo; becomes 1, click stop, and the result is similar to the screenshot below.\nOpen the command line and test whether telnet can connect successfully. If the command cannot be found, start the telnet service of Windows.\n1 telnet 192.168.1.1 Then enter the username root; try the password Hw8@cMcc or adminHW. If successful, the result is as follows:\nGet the username and password ciphertext 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 WAP\u0026gt;su success! SU_WAP\u0026gt;shell BusyBox v1.30.1 () built-in shell (ash) Enter \u0026#39;help\u0026#39; for a list of built-in commands. profile close core dump WAP(Dopra Linux) # ls bin dev init linuxrc root sys var boot etc lib mnt sbin tmp bundle html libexec proc share usr WAP(Dopra Linux) # cd /mnt/jffs2/ WAP(Dopra Linux) # ls CfgFile_Backup dypack_debug mount_ok CfgwithoutlineD factory_file mount_osgi_ok DHCPlasterrwan1 fsok nffruntimes DHCPlasterrwan5 ftvoipcfgstate oldcrc FTCRC hard_version onlinecounter InformFlag hw_boardinfo ontstatusfile TelnetEnable hw_boardinfo.bak optic_init_par.bin Updateflag_bak hw_bootcfg.xml ppplasterr258 UpnpExpandFirstInit hw_ctree.xml ppplasterr259 V5_TypeWord_FLAG hw_ctree_bak.xml reboot_bind_tag app hw_default_ctree.xml reboot_info asan_test hw_default_ctree2.xml recovername backup_ok hw_hardinfo_feature request_ddr board_type hwflashlog.bin request_ddr_inner bob_type hwkeyinfogetlog.bin resetkey ceaseadv.conf hwnfflog.bin restore certs hwontdebuglogctrl.bin result_ddr customize hwontdebuglogdata.bin scflie_0 customize.txt hwontlog.bin scflie_1 customizepara.txt keyreleasecount.txt smooth_finish cwmp_rebootsave kmc_need_backup typeword dhcp6c kmc_store_A upgrade_info.xml_back dhcp_data_a kmc_store_B xmlcfgerrorcode dhcp_lastip lastsysinfo.tar.gz dhcpc main_version WAP(Dopra Linux) # cp /mnt/jffs2/hw_ctree.xml /mnt/jffs2/mycfg.xml.gz WAP(Dopra Linux) # aescrypt2 1 mycfg.xml.gz tem WAP(Dopra Linux) # gzip -d mycfg.xml.gz WAP(Dopra Linux) # grep WebUserInfoInstance mycfg.xml \u0026lt;X_HW_WebUserInfoInstance InstanceID=\u0026#34;1\u0026#34; ModifyPasswordFlag=\u0026#34;0\u0026#34; UserName=\u0026#34;user\u0026#34; Password=\u0026#34;$2sN}QKqrgY(,w8^GHpW7)$|L3MQ)tWIkZv5Na2Z1E$\u0026#34; UserLevel=\u0026#34;1\u0026#34; Enable=\u0026#34;1\u0026#34; Alias=\u0026#34;cpe-1\u0026#34;/\u0026gt; \u0026lt;X_HW_WebUserInfoInstance InstanceID=\u0026#34;2\u0026#34; ModifyPasswordFlag=\u0026#34;1\u0026#34; UserName=\u0026#34;CMCCAdmin\u0026#34; Password=\u0026#34;$2I3^R(k3[.)B9I4E8:S!DF!Q$ULd6S(U7RRH^2]2-=Nxs\u0026amp;amp;S`J6))+2$S8\u0026amp;quot;\u0026amp;apos;j\u0026amp;amp;$\u0026#34; UserLevel=\u0026#34;0\u0026#34; Enable=\u0026#34;1\u0026#34; Alias=\u0026#34;cpe-2\u0026#34; PassMode=\u0026#34;0\u0026#34;/\u0026gt; WAP(Dopra Linux) # success! SU_WAP\u0026gt; Find the keyword user and password fields.\nThe ciphertext of the CMCCAdmin user password in the above figure is $2I3^R(k3[.)B9I4E8:S!DF!Q$ULd6S(U7RRH^2]2-=Nxs\u0026amp;amp;S`J6))+2$S8\u0026amp;quot;\u0026amp;apos;j\u0026amp;amp;$\nOpen the file huawei.exe in the Huawei secondary password cracking tool S1S2 Voice Full Authentication.zip, enter the password in the ciphertext decryption, try 3 decryption methods, and get the password as CMCCAdminFf2IrXFt\nLog in to the optical modem as a superuser Username CMCCAdmin, password CMCCAdminFf2IrXFt, found that the connection mode can be modified.\nDownlink link：https://pan.baidu.com/s/101GrTj53T4RaIpc0h4KAoQ\nExtraction code：adja\nreference https://www.eaglemoe.com/archives/216 2022-06-18 Updated\n","date":"2022-06-18T15:43:59+08:00","image":"https://adja.com.cn/p/crack-the-optical-modem-superuser-password/cover_hu_46fa2d809497bc3f.jpg","permalink":"https://adja.com.cn/en/p/crack-the-optical-modem-superuser-password/","title":"Crack The Optical Modem Superuser Password"}]