[{"content":"记录2025年的国庆 今天是国亲假期的最后一天，明天又要开始工作了。趁着假期的最后一天，记录一下这次国庆假期的生活，顺便总结下最近的生活状态。\n国庆假期的生活 这次国庆期间，几乎都待在家中，父母在第一天晚上便赶到了合肥。比较烦心的是，后面几天父母一直撮合着自己和线上平台的相亲对象见面，第五天时双方父母和子女约着吃了顿饭，双方父母都挺满意的，但相亲对象并不是自己喜欢的类型，后续也没有继续联系。\n假期的第六天是中秋节，一家人待在家里吃了顿团圆饭，第七天父母便回老家了，和同学开黑打打游戏，第八天独自宅在房间里总结下这次假期的生活。\n总体上说，这次国庆假期过得比较平淡，父母催婚的事情暂时告一段落了，后面不会过度干涉我的生活，又可以恢复到三点一线的生活状态了。\n近期生活状态总结 自从7月份之后，工作就开始忙碌起来了，开始逐渐分担一些领导的工作，每周会对上周的问题进行汇总，或者分享一些开发经验、团队合作的规范等。\n由于花在工作上的时间增多，需抽出时间汇总所有成员的问题，但经常遇到成员不参与的情况，因此在没什么可汇报的情况下，只能抽出时间来整理开发文档，或者学习一些新的技术。\n工作之余开始了长跑，目前已经坚持了两个多月，累计跑步接近100公里，争取这周完成100公里成就，后面会一直坚持下去。\n2025-10-08 更新\n","date":"2025-10-08T11:39:09+08:00","image":"https://adja.com.cn/p/national-day-records-in-2025/cover_hu_8345905b907ae457.jpg","permalink":"https://adja.com.cn/p/national-day-records-in-2025/","title":"记录2025年的国庆"},{"content":"长期规划 过去的自己一直焦虑，想得太多，折腾太多，但却没有足够突出的成果。现在想来，可能是因为没有一个明确的目标和规划，导致了这种焦虑。\n接下来的时间里，我会尝试使用一些效率工具，制定长期的规划，此外平时还要注意锻炼，注意维持清爽的外表，多出去走走认识志同道合的人，也期望能找个互相促进的伴侣。\n接下来，会定期更新这个规划，看看自己是否在朝着目标前进。\n时间 规划 完成度 2024.11~2025.2 rust基础 √ 2025.3~2025.4 dart基础 √ 2025.4~2025.8 学习flutter 10% 2025.4~2025.11 学习godot 0% 2025.6~2025.11 egui 30% 2025.6~2025.12 找对象 0% 2025-04-20 更新\n现在是2025年5月6日，劳动节假期刚结束，恰好大学期间买的服务器到期了，然后琢磨了下cf的pages和workers，为了减少麻烦，后续会将网站托管到cf上，原来的域名也会继续使用。\n此外，原先使用0.128.2版本的hugo构建网站，最新版本已经更新到0.147.1，主题也变更了好多，趁着这次节日全都更新了一遍。\n关于学习flutter和godot的计划，然后有对比了其他渲染引擎，总觉得技术发展太快了，还是得要深入底层，暂时还是按照原计划进行。\n在找对象方面，期间尝试了一次线上交友，感觉对方都挺被动的，估计只能做陌生人了，父母也在网上和家长谈，但感觉大都没效果，一切随缘。\n父母在假期来了工作地，一家子回老家玩了下，老家的镇子上感觉变化挺大的，新建的房子等待入住了，旅游景点在正在动工，等竣工后，人流量可能会多点，期望以后老家越来越好吧。\n2025-05-06 更新\n今天是5月25日，2个星期前，每周都假期改为双休了，这样有更多时间投入感兴趣的事情上了。\n在网上看了些关于图形界面开发的文章，比如APP开发框架(flutter、react native、tarui等)和游戏引擎(godot、unity、cocos、bevy等) ，感觉原来的想法太天真了，既想做APP又能做游戏，于是犹豫着学习哪个引擎，甚至还下载了unity。\n如果想快速产出，得放弃godot，把时间都投入到flutter上，业余的话顺便了解下rust相关的开发。\n2025-05-25 更新\n已经到7月21日，已经过去了两个月多了，2个月前在对比了各种GUI框架后，决定暂时放弃flutter，后续一直在琢磨egui。\n由于egui的循环中不允许异步等待操作，必须使用通道来传递数据，当事件产生，app保留接收通道，后台创建线程来处理数据，处理完后通过通道发送数据到app中，每次循环app都会检查接收通道数据，接收到数据后更新界面。\n在尝试将简单的异步操作集成到egui中时，还需要解决多线程的共享资源问题，使用Arc\u0026lt;Mutex\u0026lt;T\u0026gt;\u0026gt;来共享数据；如果在多个线程中同时读写操作，则需要使用RwLock\u0026lt;T\u0026gt; 来共享数据。\n此外，代码复用、结构方面也需要考虑，使用egui的App trait来定义应用程序的结构，使用egui::Context来管理状态和事件，最近找到了可供参考的项目，希望能对后续开发有所帮助。\n2025-07-21 更新\n距离上次更新已经过去了一个月，由于开始负责组内的问题跟踪和处理工作，业余的空闲时间少了许多，每天晚上如果加班到9点的话就去旁边的公园跑一圈，回头再看打卡记录，虽然不是每天都能坚持，但从7月中旬开始，平均下来每周中有3天时间锻炼，后面继续保持。\n业余的学习中，简单使用过egui，发现做复杂功能，如果设计能力较差，代码维护起来比较费力，于是我开始关注起Bevy，它的设计理念和ECS架构让我眼前一亮，最近大概了解了下Bevy的基本概念，后续会尝试用Bevy来做一些小项目。\n2025-08-24 更新\n","date":"2025-04-20T09:34:35+08:00","image":"https://adja.com.cn/p/long-term-planning/cover_hu_f6d19d11acdef439.jpg","permalink":"https://adja.com.cn/p/long-term-planning/","title":"长期规划"},{"content":"异地组网联机游戏 毕业后，同学们都奔赴各地忙着升学和事业，放假时偶尔会开黑打一两局魔兽，但由于身处不同省份，局域网游戏联机有点麻烦。\n期间尝试过蹭免费组网工具、自建中转服务器、贝锐蒲公英组网，通过对比，希望大家能找到适合自己的组网方式。\nEasyN2N或N2N 由于最开始用的EasyN2N，体验还不错，从相关社区中还能学习到一些网络知识。\n但是，由于EasyN2N的中转服务器是免费的，所以在大家都在用的时候，会出现中转服务器负载过高，导致延迟过高，甚至无法连接的情况，在毕业回老家后，老家那边的网络较差，经常玩到一半掉线。\n此外，EasyN2N经常被杀毒软件误删，也可能导致中途掉线，所以建议推荐通过命令行的方式来使用，而不要使用它自带的可视化工具。\n相关的使用可参考该文章\n贝锐蒲公英 贝锐蒲公英是一个收费的组网工具，3人以内免费，如果是超过3人的组网，需要购买套餐。\n免费版的贝锐蒲公英不能设置虚拟局域网客户端的IP，有些游戏比如魔兽就需要抓包分析下，可以发现B客户端无法收到A客户端广播的udp报文，所以得要通过网络调试助手来辅助创建房间，下面是具体的操作步骤：\n假设存在A、B两台电脑，A电脑的IP地址为172.16.3.130，B电脑的IP地址为172.16.3.150，子网掩码都为255.255.252.0。\n假如B电脑作为房主创建房间，A电脑作为客户端加入房间 通过Wireshark抓包可以发现，B电脑创建房间后会一直向udp的6112端口广播f732100001000000010000000c000000，由于时间有限就不分析报文含义了。\n当A电脑扫描存在的房间时，A电脑会向udp的6112端口广播f72f1000505833571a00000000000000，由于A和B不在同一个网段，所以B电脑无法收到A电脑的广播，A便无法知道是否存在房间。\n接着，我们通过网络调试助手在A电脑上向B电脑发送用于扫描房间的udp广播包，假设收到报文msg(包含了玩家人数、地图信息等)。\n然后，在B电脑上将msg的内容发送给A电脑，A电脑就可以加入房间了。\n总结 如果需要组网的客户端较少，N2N和贝锐蒲公英都是较低成本的组网方式。\n如果有更进一步的需求，比如房间人数较多，或者需要更稳定的网络，如果玩家主要集中在几个地区，可以考虑自建中转服务器，如果玩家分布较广，可以考虑购买贝锐蒲公英套餐。\n参考 https://bugxia.com/n2n_launcher_param\nhttps://www.cnblogs.com/flying_bat/archive/2008/06/24/1228627.html\n2025-02-22 更新\n","date":"2025-02-22T19:21:36+08:00","image":"https://adja.com.cn/p/remote-networking/cover_hu_78ce9c8e0514c0eb.jpg","permalink":"https://adja.com.cn/p/remote-networking/","title":"异地组网联机游戏"},{"content":"对2024年的总结 距离刚开始工作已经过去了一年多，这一年多的时间里，我经历了很多事情，也学到了很多东西。这篇文章就是对2024年的一个总结。\n工作上 我的工作内容主要负责单片机的固件开发，经过一年的锻炼，可以初步胜任这个工作。在这一年里，我学到了很多东西，比如团队合作、开发工具使用技巧，还有单片机的常用外设的使用等。\n期间也遇到了很多问题，但在领导和同事的帮助下，都得到了解决。每次遇到问题，我都会先自己思考，然后在掌握的基础上想着如何去改进，比如提高代码的可读性、复用性、使用的便利性等，在每个细节上，都尽量做到最好。\n工作之余，还尝试着学习了一些新的技术，并努力将其应用到工作中，比如使用Renode来提高固件开发的效率，尝试gitlab的CI/CD来编译固件等。尽管做了很多努力，但效果不是太好，主要由于缺少成员的参与，工作量太大，时间太紧等原因。\n生活上 由于毕业就独自前往异地工作，所以生活上的一切都要自己来打理，这对我来说是一个挑战。\n由于住的非常偏僻，再加上性格等原因，平时基本上宅在家中，空余时间看小说、打魔兽、折腾一些技术等。\n上半年趁着不忙的时候，将博客由hexo迁移到hugo，这样可以更方便的写文章，也更容易维护。\n此外，有空的话就和同学开黑，这样可以放松一下，也可以和同学们保持联系。\n2025年的展望 尽管在毕业即失业的2023年找到了工作，但考虑到未来毕业生仍然保持上升的趋势，未来的竞争会更加激烈，业余还需要不断保持对技术的敏感度，有机会认识更多人。\n此外，在和朋友开黑的过程中，异地组网比较麻烦，接下来我会尝试参考一些开源项目，开发一个简单的组网工具。\n2023-02-02 更新\n","date":"2025-02-02T12:38:52+08:00","image":"https://adja.com.cn/p/summary-of-2024/cover_hu_3b521bf98819ec8b.jpg","permalink":"https://adja.com.cn/p/summary-of-2024/","title":"对2024年的总结"},{"content":"使用Git进行团队合作 自上次迁移博客便好久没有更新了，这次更新的内容是关于如何使用Git进行团队合作。这篇文章主要介绍团队合作的工作流程。\n基础教程 这篇文章假设你已经对Git有一定的了解，如果你对Git还不太熟悉，建议你先阅读一些关于Git的基础教程，比如廖雪峰的Git教程。\n此外，还推荐参考以下教程：\nGit官方文档：\nGit官方文档适合初学者和高级用户。 Pro Git书籍\nPro Git是一本免费的电子书，涵盖了 Git 的基础知识和高级用法，非常适合团队合作。 如果你已经对Git有了一定的了解，那么我们就可以开始介绍如何使用Git进行团队合作。\n团队合作的工作流程 在GitLab中，仓库成员有5种角色：\nGuest(访客)：只能查看仓库内容，不能进行写操作； Reporter(报告者)：可以查看和克隆仓库，但不能进行写操作； Developer(开发者)：可以进行写操作，但不能管理项目设置； Maintainer(维护者)：可以管理项目设置和成员； Owner(所有者)：拥有所有权限，包括删除项目。 假设有一个项目，团队成员包括项目经理(1人)、开发者(3人，其中1人中途加入)、测试者(1人)等共5人;\n这5人的角色及职责如下：\n项目经理：Owner 开发者1：Maintainer(负责开发、审核代码) 开发者2：Developer 开发者3：Developer(中途加入) 测试者：Reporter 在开发者3加入之前，项目开发都为团队内部合作开发，代码都应该提交到一个仓库。\n在开发者3加入之后，项目涉及到跨团队开发，开发者3应该fork仓库，如果使用GitLab，则通过Merge Request(简称MR)的方式来将代码合并到上游仓库(上游仓库为被fork的仓库)；\n下面按照GitLab Flow工作流说明。\n项目经理创建仓库，提交需求文档，并添加团队成员为Developer 初次提交如下：\n1 2 3 4 5 6 git init . touch README.md #该文章简要介绍下项目背景及作用 git add README.md #添加README.md到暂存区 git commit -m \u0026#34;first commit\u0026#34; git remote add origin https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/xxx.git #添加远程库，这里修改成自己的远程库 git push -u origin master 接着提交需求文档：\n1 2 mkdir docs #创建docs目录，在该目录下添加需求文档 touch docs/requirements.md #采用markdown格式记录需求文档 打开docs/requirements.md文件，完成编写需求文档后操作如下：\n1 2 3 git add docs/requirements.md #将需求文档添加到暂存区 git commit -m \u0026#34;[docs] 添加需求文档\u0026#34; git push origin master 开发者1提交技术文档，开发者1创建dev分支 提交技术文档操作如下：\n1 2 3 git remote add origin https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/xxx.git #添加远程库，这里修改成自己的远程库 git fetch origin -a #获取远程库所有分支 touch docs/technical.md #采用markdown格式记录技术文档 打开docs/technical.md文件，完成编写技术文档后操作如下：\n1 2 3 4 5 6 git add docs/technical.md #将技术文档添加到暂存区 git commit -m \u0026#34;[docs]添加技术文档\u0026#34; git push origin master git checkout -b dev #创建并切换到dev分支 git push origin dev 团队内部合作 团队内部合作时，开发者1、开发者2、测试者都在同一个团队中，他们都是项目的成员，可以直接提交代码到同一个仓库；\n接下来按照GitLab Flow工作流程说明两种应用场景。\n开发新功能 开发和测试新功能不能都在一个分支上修改，而应该创建新分支，命名为feat_xxx表示开发xxx功能。\n接下来介绍开发者1提Issue并在该Issue中创建2个新分支分别名为feat_xxx和test_xxx，用于开发者2提交功能代码到feat_xxx分支和测试者提交用例代码到test_xxx分支中。\n其中，feat_xxx分支是基于最新的dev分支，test_xxx分支是基于feat_xxx分支，工作流如下：\n开发者1按照dev分支的文档提Issue，开发者1在该Issue中基于dev分支创建新分支feat_xxx，并通知开发者2开发该功能\n开发者2获取并checkout到feat_xxx分支\n不存在feat_xxx分支则需要创建并切换到新分支，执行以下指令：\n1 2 git fetch origin -a #获取远程库所有分支 git checkout -b feat_xxx origin/feat_xxx #基于远程的feat_xxx分支在本地创建feat_xxx分支，并切换到该分支 已存在feat_xxx分支则执行以下指令：\n1 2 git checkout feat_xxx #不需要-base参数，因为已经存在本地feat_xxx分支 git pull origin feat_xxx:feat_xxx #拉取远程feat_xxx分支到本地feat_xxx分支 开发者2在feat_xxx上进行开发，开发完成后并push到远程库 1 2 3 git add \u0026lt;files\u0026gt; git commit -m \u0026#34;[feat]添加xxx功能\u0026#34; #\u0026#34;[feat]\u0026#34;表明这是新增功能 git push origin feat_xxx 注意：修改feat_xxx如果是新增功能，则提交记录的注释应该添加前缀\u0026quot;[feat]\u0026quot;\n开发者2此前没有提MR，则创建MR请求将feat_xxx合并到dev分支，需将Issue和该MR关联起来 其中在开发者2需要在完成新功能后，需在Issue中关联MR，通过!\u0026lt;MR_number\u0026gt;的方式，假设该MR的序号为9，则应该在Issue中添加注释See merge request !9；\n同样在Merge Request中添加注释表明这是对应哪个Issue，通过#\u0026lt;Issue_number的方式，假设该MR对应的Issue为5，则添加注释See issue #5。\n开发者1审核代码，审核不通过则在MR中说明改进建议，并回到步骤(3) 这里提交记录的注释仍应该为[perf]改进xxx，这里的\u0026quot;[perf]\u0026ldquo;为针对xxx做出的改进\n开发者1审核通过则在该Issue中创建子项Issue，基于feat_xxx分支创建test_xxx分支，将该Issue分配给测试者 注意：这里开发者1审核通过不应该通过MR，需要等测试者提交测试用例后并测试通过，然后测试者需要提MR请求将test_xxx分支合并到feat_xxx分支，之后开发者1才能通过确认MR，feat_xxx才被删除；\n测试者拉取测试分支代码，编写测试用例并提交到test_xxx分支 1 2 3 4 5 6 7 #已存在test_xxx分支则执行以下指令 git checkout test_xxx #第一次拉取时执行：git checkout -b test_xxx origin/test_xxx touch test/test_xxx #编写测试脚本 #编写脚本可以为其他语言编写的测试用例 git add test/test_xxx git commit -m \u0026#34;[test]测试xxx功能\u0026#34; #提交记录注释的\u0026#34;[test]\u0026#34;，表明它修改了测试代码 git push origin test_xxx 无论测试用例是否正确，都应该提交测试用例程序，且提交记录前缀应该为\u0026rdquo;[test]\u0026quot;，表明这是测试用例。\n测试者此前没有提出MR，则创建MR请求将test_xxx合并到feat_xxx分支中，需将Issue和对应的MR关联\n开发者2审核测试者的MR，不通过则回到步骤(10)，否则交由开发者1审核，开发者1审核通过则允许合并\n开发者1允许合并将会删除test_xxx分支，然后该MR将被关闭，还需要开发者1标记测试Issue为已完成\n开发者1、开发者2更新feat_xxx，可以先本地测试，若存在问题，则回到步骤(3) 1 2 3 git fetch origin feat_xxx git checkout feat_xxx #切换到要合并的本地分支 git merge origin/feat_xxx #将远程库合并到当前分支 测试用例都通过则由开发者1确认通过MR，将feat_xxx合并到dev分支中 添加新功能的时序图如下所示：\n也可以简单的按照如下图理解：\n处理集成时的问题 单独测试某功能时，该功能一切正常，但在集成时出现问题，便以下面这个示例介绍。\n假设需求没有较大变化，原来已有功能feat_xxx1(不存在问题)，添加新功能feat_xxx2，单独测试feat_xxx2也不存在问题，但在集成测试后出现了问题，测试者需要先提出Issue，其他成员都应该积极讨论定位问题；\n这里不用回到feat_xxx2的分支修复问题(可能feat_xxx1的问题在先前的集成测试中没暴露出来)，而是在集成后的dev分支上创建新分支来修复集成问题，\n具体工作流如下：\n测试者基于dev分支进行测试，测出问题则提Issue，说明问题的现象和执行了什么操作 如果该问题是在某次测试用例中出现，则应该提交测试用例程序然后提交MR请求将test_dev合并到dev分支，然后在Issue中关联MR和对应Issue\n如果其他成员讨论确认存在问题，则在开发者1、开发者2通过测试者的MR后，由开发者1确认合并，test_dev分支将被删除\n注意：\n可能同时在开发feat_xxx3和feat_xxx4功能，每个功能单独测试都没问题，但在集成后出现问题，它们恰好没有冲突地被合并到dev分支，测试者应当在本地新建两个新分支针对这两次集成，针对feat_xxx3合并到dev的提交，则创建test_dev分支，针对feat_xxx4合并到dev的提交则创建test_dev1分支，分支命名依次类推。\n如果连续多次合并到dev分支，包括添加新功能、修复旧功能的问题，则应该通过如下指令创建tag：\n1 2 3 git checkout dev git tag release-x.x.x #切换到dev分支，将当前分支创建为一个发布版本 git push origin release-x.x.x #将该版本推送到远程 一般情况，测试者是在release-x.x.x的分支上测试代码，如果存在问题则在本地创建test-release-x.x.x分支来测试，操作如下：\n1 2 3 4 5 git fetch origin -a git checkout -b test-release-x.x.x origin/release-x.x.x #基于远程发布版本创建测试分支 #测试，如果存在必现的问题则提交对应的测试用例，需要进行以下操作 git commit -m \u0026#34;[test]测试发布版本x.x.x\u0026#34; git push origin test-release-x.x.x 在定位问题(假设问题出现在开发者2开发的feat_xxx2)后，则开发者1在Issue中基于存在问题的dev分支创建fix_xxx2分支，并将其指派给开发者2\n开发者2需在fix_xxx2上修改和提交代码\n这里的提交记录注释为[fix]修复xxx问题\n开发者2进行和测试者同样的操作，若问题仍浮现则回到步骤(3)\n开发者2提交MR请求将fix_xxx2合并到dev分支中，并将该MR和对应的修复Issue关联起来\n测试者2拉取fix_xxx2进行测试，没有问题后则通过，但不会合并到dev分支\n开发者1观察到bug修复，则最终通过合并，fix_xxx2分支将被删除\n跨团队开发工作流 在开发者3加入后，开发者3会因缺乏注意事项导致提交的代码影响到已有功能，因此开发者3应该fork上游仓库来开发，其他成员仍然按照原来的方式开发。\n开发者3应该如下操作：\n1 2 3 git clone https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/repo-xxx.git #克隆fork的仓库到本地 cd repo-xxx git remote add upstream https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/repo-xxx.git #添加被fork的仓库为上游仓库 假设项目紧急，本应该由开发者2实现的功能交由开发者3开发，则开发者1应当在上游仓库中提出Issue，基于dev分支创建feat_xxx分支，开发者3收到通知，则应该如下操作：\n1 2 git fetch upstream feat_xxx #获取上游仓库的feat_xxx分支 git checkout -b feat_xxx upstream/feat_xxx 此后的操作和团队内开发工作流类似。\n注意：\n开发者3如果需要提MR，则应当在自己fork的仓库创建MR；\n开发者3如果接收到某个指派任务，则应当从上游仓库upstream中拉取对应分支到本地，然后在该分支上修改和提交代码\n开发者3不能直接push到上游仓库，而应该push到fork的仓库，然后创建MR请求合并到上游仓库的对应分支，需要在上游仓库中将该MR和对应Issue关联起来。\n补充 MR后远程库的分支被删除，如何删除本地fetch的远程库 开发者1确认MR后，远程库的feat_xxx分支被删除，但本地的feat_xxx仍存在\n1 2 3 4 git fetch -p #-p为--prune缩写 git checkout dev #如果当前在feat_xxx分支上 git branch -d feat_xxx #删除本地feat_xxx分支 git branch -D feat_xxx #注意：意味着本地分支没被合并，会被强制删除 某发布版本存在较大问题，如何删除本地存储的已删除远程库tag 1 git fetch -P #-P为--prune-tags缩写 跨团队合作中，上游仓库MR后，如何将fork的远程库与其上游仓库同步 假设自己MR请求将fix_xxx合并到上游仓库的dev分支，开发者1确认合并后，则操作如下\n1 2 3 4 5 6 7 8 git fetch upstream -a #获取上游仓库的更改 git merge upstream/dev dev #将上游仓库同步到本地dev分支 #or git pull upstream dev:dev #代替上面2行指令 git push origin dev #将本地更改同步到fork仓库中 git checkout dev #如果当前在fix_xxx分支 git branch -d fix_xxx #删除本地fix_xxx分支 git fetch -p #删除本地存储的已删除的fix_xxx分支 如何给新建分支命名 比如，添加新功能添加查询温度功能，应该在当前分支(一般为dev分支)创建名为feat_query_temp的新分支(其中feat为feature的缩写);\n新分支命名格式如下:\n1 type_subject 提交类型(type): 包括feat(新功能)、fix(修复问题)、doc(文档更改)、refactor(代码重构，不是新增功能，也不是修复bug)、test(添加或修改测试)、chore(其他不修改源码或测试用例的提交)、style(代码格式，不影响代码运行);\n简短描述(subject): 使用下划线_分割单词，要求简洁明了.\n命名规则示例如下:\n1 2 3 4 feat_support_eth #支持网口 refactor_cmd_resp #重构指令回复提示信息 style_format_code #格式化源代码 test_cmd_resp #测试指令回复提示信息 如何编写提交注释 提交注释尽量做到简介明了，直观反映提交代码的更改;\n也应该做到新功能和修复bug的代码应该分为2次来提交，其他类型的提交也应当如此;\n可以通过git commit -m \u0026lt;message\u0026gt;指令来提交到本地库，其中\u0026lt;message\u0026gt;的说明如下所示:\n1 格式: [type]msg 其中，type取值及其含义如下:\ntype 含义 示例 feat 新功能(feature) [feat]添加健康检查 fix 修复问题(fix bug) [fix]修复健康检查归位问题 doc 文档更改(documentation) [doc]完善技术文档 style 代码格式化 [style]格式化非生成的源码 refactor 重构代码 [refactor]重构指令回复提示 test 添加或修改测试 [test]测试健康检查 chore 不修改源码或测试文件的提交 [chore]完善.gitignore perf 提高性能的更改 [perf]提高滑动平均性能 ci 持续集成相关的更改 [ci]能自动生成并发布hex和bin文件 build 构建系统或外部依赖的更改 [build]完善CMakelists.xt配置 revert 撤销之前的提交 [revert]回退定时任务 每次提交如何自动执行特定操作 假如每次提交前都要格式化代码，正常情况下应该通过主动进行特定操作，但可通过配置.git/hooks/pre-commit来执行想要的操作，示例如下：\n1 2 3 4 5 6 git clone https://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/path/to/repo_xxx.git cd repo_xxx.git touch .git/hooks/pre-commit #在.git/hooks目录下创建pre_commit文本文件 #编辑pre-commit内容 chmod +x .git/hooks/pre_commit #修改pre-commit属性为可执行 其中pre-commit的内容如下：\n1 2 3 4 5 6 7 8 9 10 #!/bin/sh # Find all C source files and header files files=$(git diff --cached --name-only --diff-filter=ACM | grep -E \u0026#39;\\.(c|h)$\u0026#39;) # If there are no files to format, exit [ -z \u0026#34;$files\u0026#34; ] \u0026amp;\u0026amp; exit 0 # Run clang-format on each file with the specified .clang-format file echo \u0026#34;$files\u0026#34; | xargs clang-format -i --style=file # Add the formatted files back to the staging area echo \u0026#34;$files\u0026#34; | xargs git add exit 0 通过上述配置后，每次执行git commit后它会在修改文件中过滤\u0026quot;.c\u0026quot;和\u0026quot;.h\u0026quot;的文件，然后存在该文件则通过clang-format并按照根目录下的\u0026quot;.clang-format\u0026quot;配置文件来格式化该文件。\n参考 https://www.cnblogs.com/xiaoqi/p/gitlab-flow.html\nhttps://www.atlassian.com/git/tutorials\nhttps://git-scm.com/book/\nhttps://docs.github.com/zh/get-started/start-your-journey/about-github-and-git\n","date":"2024-10-06T11:34:59+08:00","image":"https://adja.com.cn/p/teamwork-using-git/cover_hu_68aa3635992a5706.jpg","permalink":"https://adja.com.cn/p/teamwork-using-git/","title":"使用Git进行团队合作"},{"content":"使用DDNS访问内网设备 有时出门需要访问家中的nas，由于国内的公网ipv4越来越难申请，且群晖官方的quickConnect服务速度也很慢，在参考相关教程后，决定通过DDNS将域名解析到公网ipv6，然后直接通过域名访问内网设备；\n在先前光猫破解获取超级用户修改桥接的实验基础上，我将路由器连接光猫，由路由器来拨号并开启ipv6，在分配到公网的ipv6后，便开始DDNS配置过程.\n通过群晖的DNS服务 从\u0026quot;控制面板-\u0026gt;外部访问-\u0026gt;DDNS\u0026quot;点击新增，选择服务供应商为Synology，下面自定义配置； 注意，ipv6开头要为240开头的(电信为240e；移动为2409；联通为2408)，fe80开头的一般为内网ipv6\n需要https访问的话，勾选\u0026quot;从Let\u0026rsquo;s Encrypt获取证书\u0026quot;，点击确定.\n使用其他供应商的DNS服务 以下仅以腾讯云的DNS服务为例，需要预先在腾讯云官网申请一个域名;\n使用ddns-go镜像 进行动态域名解析，需要自己的nas设备定时的查询本机的ip地址，然后调用更新域名解析字段的接口，从而实现ddns；\n所以不能需要换个方法，网上有很多方法，这里我提供一个采用docker进行DDNS更新的方法； 在套件中心种搜索docker，安装docker，步骤略；\n打开docker，选择\u0026quot;注册表\u0026quot;，搜索ddns，安装第一个\u0026quot;ddns-go\u0026quot;\n安装完成后打开映像，选择ddns-go，点击启动；\n点击高级设置-\u0026gt;存储空间-\u0026gt;添加文件夹；\n修改装载路径，我的配置如下：\n点击网络-\u0026gt;勾上host网络-\u0026gt;应用；\n点击下一步，点击完成.\n配置DDNS 打开http://[域名对应的nas的ip]:9876/\n配置DNS服务商，选择腾讯云，输入ID与Token，注意，这里的ID与Token对应\u0026quot;DNSPod Token\u0026quot;，不是\u0026quot;腾讯云API密钥\u0026quot;，链接是https: //console.dnspod.cn/account/token/token\n只启用ipv6，我的配置如下：\n在点击\u0026quot;Save\u0026quot;之前，需要配置下域名解析，添加AAAA类型(表示ipv6地址)记录，随便填下，它会自动更新，我的配置如下：\n配置完成后点击保存，右边会出现最新的历史记录；\n应该出现\u0026quot;更新域名解析 xxxxxx 成功\u0026quot;或“更新域名解析 xxxxx 没有变化”\n通过域名+端口来进行测试.\n补充 在2022年的暑假，搭建完成后我请同学帮测试了江苏不同地级市的速度，速度还是挺快的;\n后来毕业后去了其他省，在找到第一份工作后重新想起nas然后试着重新搭建，但发现同样的方法完全行不通，主要因为不同省份网络基础设施的完善度差别很大;\n如果在ipv6都未推广开的省份，还是建议少折腾，此外因为过去几年PCDN的泛滥，运营商会根据带宽的上行速度查看用户有没有搭建PCDN，如果DDNS被恶意使用，可能导致宽带被封.\n2022-06-19 记录\n2023-07-07 更新\n","date":"2024-07-06T16:08:49+08:00","image":"https://adja.com.cn/p/use-ddns-to-access-intranet-devices/cover_hu_b5ef505a63f32487.jpg","permalink":"https://adja.com.cn/p/use-ddns-to-access-intranet-devices/","title":"使用DDNS访问内网设备"},{"content":"开发环境管理工具 开发时，时常用到多开发环境，大家可能用到过类似miniconda、nvm和gvm的工具，它们分别用于管理python、nodejs及go的版本; 此外还有如maven的包管理工具;\n如果用到新的编程语言或包管理工具，安装对应的版本管理工具都比较麻烦，接下来介绍3款开发环境管理工具asdf、mise和vfox.\nasdf、mise和vfox的对比 三者都是用于管理开发环境的工具，都提供统一的命令行指令，可通过安装插件来拓展其功能.\nasdf 其中asdf诞生的时间更早，插件生态更加完善，它主要采用shell脚本开发，能非常好地适配于Linux及Mac，当谈到对Windows的支持时，有人向官方提出了类似的issue，但后续未提供支持Win的版本;\n当然，如果非要在Win平台使用asdf，可在wsl中安装使用，但考虑到wsl的速度远不如原生的exe格式程序，再加上shell本身为解释执行的，速度就更慢了; 因此，除了Win平台，其他平台都推荐使用asdf.\nmise 该工具原名rtx，由于原名很容易与Nvidia的显卡名混淆，后更名为mise，它采用rust编程语言开发;\n由于后端采用asdf，它也继承了asdf的缺点，同样对Win平台支持比较差.\nvfox vfox采用go编程语言开发，相对于另外2款工具，它最后编译成可执行文件，因此，速度快了很多，体积也较小，对Win平台也提供了原生支持.\n美中不足的是，可能这类工具的使用者大多采用Linux与Mac系统，vfox的贡献者较少，功能有待完善，但后续应该会超过前两者.\n总结 比较三者的特点，我更偏向于使用vfox管理开发环境，尽管如此，日常仍会使用语言专用的版本管理工具比如miniconda;\n即便学了很多编程语言，但日常大多人主要使用3门及一下的编程语言; 解决3款工具的安装及使用相对于解决1款工具bug的难度，前者花费的时间更少，不至于寻遍方法而只能提issue;\n此外，最近我在折腾自动化工具的过程中，发现环境的配置愈发简单，Dev Container对软件开发算是福音，或许未来任何平台的开发者都不必关注环境的安装配置，期待这一天的到来.\n2024-06-19 更新\n","date":"2024-06-19T07:34:46+08:00","image":"https://adja.com.cn/p/dev-environment-management-tools/cover_hu_d836b88666e47319.jpg","permalink":"https://adja.com.cn/p/dev-environment-management-tools/","title":"开发环境管理工具"},{"content":"博客迁移 距离上次写文章接近5个月了，期间主要忙于工作中，即便空闲时也没有抽时间查漏补缺，直到前个月差不多在4月中旬，我逐渐想摆脱这种状态，于是从自己感兴趣的方面入手，下面回顾下过去的遭遇.\n起因 毕业入职半年以来，除了日常娱乐外，我时常浏览Github、和朋友出去聚餐、或和同学组网打魔兽等，但总感觉少了什么，在朋友与同学相继工作与升学后，聚餐与一起娱乐的时间愈发少了;\n尽管每天工作中会学到新东西，但感觉仍有不足，后来想通了大概是行动的太少，被网上的焦虑裹挟着内耗，逐渐意识到再这样下去，将会永远达不到预期.\n迁移 我从5月初开始便一直考虑迁移博客，有必要考虑以下几方面来迁移博客:\n更低的学习成本 能够复用 可间接或直接接触感兴趣的方面 框架的稳定性 综合考虑，我最终选择了hugo框架，一方面hugo使用数相当多，另外未来探索网络会用到go编程语言，恰好hugo就是用go开发的;\n接着，选择一款好看的主题，hugo相对hexo来说参考文档稍少了点，最开始我是考虑的hugo-theme-bootstrap，它的中文文档写的很好，且支持博客及文档的布局，然而参与者不多，可能作者不会长时间维护，最终没采用; 后来采用了hugo-theme-stack，它几乎没有第三方依赖，中文文档比较完善;\n在完善整体布局与部分细节后，又花了半天时间琢磨Github Actions，此前使用过Jenkins构建，这次使用Github构建在认证部署公钥上卡了好久，最终还是解决了.\n规划 该反省的是，过去制定的规划我大多没有坚持下来(比如加强英语、学习FPGA与电路知识、探索计算机网络等);\n其中加强英语实在坚持不下来，索性通过支持多语种文章来学习英语; 至于计网，在工作中常接触LWIP，生活中时常会在云服务器与本地nas上折腾，后续可能会参与相关开源项目; 而谈到硬件相关的东西，我感到头疼，但由于未来工作会用到，打算把买的开发板学习起来了; 此外，还要了解新出的rust语言(和同事交流下)、学习Linux开发、学习408\u0026hellip; 头大啊，想要做的实在太多了;\n综合兴趣与工作，接下来需要完善博客、探索计网、学习FPGA与电路、抽空了解下rust语言.\n2024-06-17 首次更新\n","date":"2024-06-17T00:46:21+08:00","image":"https://adja.com.cn/p/blog-migration/cover_hu_d64c50090b23f678.jpg","permalink":"https://adja.com.cn/p/blog-migration/","title":"博客迁移"},{"content":"合肥两个月生活体验 毕业后7月底到合肥，距离现在差不多已过近2个月了，总结下最近的生活感受吧.\n作息安排 对比下在家和在校的作息，可能习惯于独处，但也让自己更加专注，除了九九六的工作外，每天会花费两三个小时学习未来工作、研究或感兴趣的专业知识；\n房间是租的每月750的单人间，卫生间是公共的，考虑到晚上有时回去已很晚，或者卫生间已被占用，如果需要洗衣，就必须尽早回去(尽量晚9点20到家)或者早上提前一小时(早上7点半之前)去洗衣，防止打扰到其他租客睡觉；\n由于到工作场所只需走路20分钟，每天早8点35左右出发，差不多提前了10分钟到工位(上午工作时间从9点开始)；\n谈到工作时间(尽管这里的工作指的是培训，或者在某些学校当作实习)，算是比较平淡的，由于已具备相当的基础，我会选择抽空学习更加底层的计算机知识，或者解决整合知识中所遇到的问题、又或弥补欠缺的专业知识；\n上午的工作从9点开始，持续到中午12点，中午2小时包括了半小时吃饭、半小时随意分配(用于看B站或者解决问题)、近1小时睡觉等；\n下午的工作从下午2点开始，持续到下午6点，然后是1小时的空闲时间，可以用来吃晚饭或做点其他事情；\n工作到晚上9点，至此一天的工作已结束，回家时我会收拾好电脑回家；\n回到家，然后打开电脑继续昨天的学习任务，有时实在累的不行便趴在桌上小睡1小时，或者实在不想学(比如想看些电影、或发现有意思的小说、又或胡子太长太硬需处理)，不想学的时候便稍微放纵一晚，第二天继续未竟的事；\n生活感受 读书时平时放假就待在家里，因为家位于乡下，周围无娱乐场所、无小摊、无饭店、五超市，导致出门、吃饭和购物非常麻烦；\n毕业后来到合肥后租房，尽管生活成本上来了，一个月差不多需要1650(750房租+900的饭钱)，但无论拿快递、购物、吃饭还是出行，都无比方便；\n然而，大城市也存在些缺点(可能对于别人来说并不是)，这里有很多桥、地铁，出行还需用到各种码，对于初次来到大城市的农村人非常不友好，再加上手机导航定位不准，令人头疼；\n租房期间，曾出现过马桶堵塞的糟心事，大概是房客习惯将卫生纸用完直接丢马桶，尽管该问题在差不多一个星期左右的时间被解决了，但这期间使用卫生间着实令人难受.\n工作感受 如果是热爱计算机的话，996的工作其实也不算什么，这过程中得到的提升还是较大的，可以学到很多有用的东西；\n近两个月的工作学习中，总感觉少了什么，后来我逐渐发现是少了初入大学时的满腔热血，尽管和我周围人相处得还可以，还时常帮他人解惑，但无形间始终存在着距离感；\n尽管如此，我仍然希望自己能保持自己，不断进步.\n未来打算 考虑到之后工作打算做驱动或底层开发，后续会在业余时间学习内核，并学习其他架构下的汇编语言；\n合肥生活的两个月，尽管总体上比在家要好很多，但仍然达不到心中预期，大概是当下生活并不符合预期，或者说接触不到足够优秀或志同道合的人，未来两至三年必去考研，但在此之前，还需要打好基础(主要是操作系统、计算机组成原理)，找到想要研究的方向；\n另外，由于合肥的产业齐全，并且有进行高新技术(核聚变、量子芯片)，无论是当下还是未来，未来都是光明的，如果将来工作，未来我大概率在合肥工作，也算是为家乡做贡献吧.\n2023-09-23 更新\n","date":"2023-09-23T14:05:34+08:00","image":"https://adja.com.cn/p/two-month-life-experience-in-hefei/cover_hu_7ea39ed252ba7dd1.jpg","permalink":"https://adja.com.cn/p/two-month-life-experience-in-hefei/","title":"合肥两个月生活体验"},{"content":"黑群晖使用体验 刚毕业想到去年在淘宝买的蜗牛星际NAS存储，直到有较充裕的时间开始折腾下;\n说明下我的NAS为四盘位的蜗牛星际，待安装的系统为7.1.0-42661，可参考该文章，由于该教程过于简陋，所以下面介绍我的安装过程，顺便补充系统使用上的问题.\n制作U盘引导 引导一定要根据系统型号与版本进行选择，一般商家会提供U盘引导，并提供了特定pat文件;后续如果升级系统，可参考该引导配置制作新的U盘引导，最好用新的U盘制作U引导，下面介绍U盘引导的制作.\n准备工作 首先需要下载必要工具，链接：https://pan.baidu.com/s/1o8v7xdCPXgh3zIocm-iPcA 提取码：adja\n先烧录7.1的镜像，再修改U盘的grub.cfg文件，待修改参数包括pid、vid、sn、mac1、mac2、netif_num、DiskIdxMap、SataPortMap和SasIdxMap;\n获取pid、vid pid和vid参数可在插入U盘后，通过ChipEasyv1.6(pid vid读取工具）.exe获取;\n获取sn、mac、netif_num sn和mac(指mac1、mac2)可保持不变，也可以采用去某宝买全洗白的sn码;\nnetif_num表示网卡数量，有1个网卡则值为1，值为网卡数;\n获取DiskIdxMap、SataPortMap和SasIdxMap DiskIdxMap、SataPortMap和SasIdxMap可参考该文章，具体取值可问卖家客服或者通过tinycore工具(镜像为网盘的tinycore-redpill.v0.9.4.9.img文件，需烧录到U盘插入NAS)，tinycore工具使用可参考该文章，由于没有显示屏只有物理机无法看到NAS重启的引导界面，并且nas不好拆机，所以DiskIdxMap等直接采用卖家提供引导U盘的参数;\nSataPortMap: 描述各控制器的接口数，比如SataPortMap=22，表示第1个控制器有2个接口、第2个控制有2个接口，SataPortMap=345，表示第1个控制器有3个接口、第2个控制有4个接口、第3个控制有5个接口;\nDiskIdxMap: 描述磁盘的顺序，用2位16进制数表示1个控制器，比如SataPortMap=22 DiskIdxMap=0002，表示第1个控制器从第0号(00)磁盘开始，第2个控制器从第2号(02)磁盘开始，又比如SataPortMap=345 DiskIdxMap=070c00，表示第1个控制器从第7号(07)磁盘开始，第2个控制器从第12号(0c)磁盘开始，第3个控制器从第0号磁盘(00)开始，假设各控制器头顺序为BCA，如果DiskIdxMap取值为00070c，则顺序为ABC;\nSasIdxMap: 不清楚具体功能，文章说按照正确的顺序，默认加上;\n烧录镜像与修改grub.cfg Diskgenius（改pid vid sn mac删除硬盘）.exe用于修改img镜像文件，但不建议修改，由于只要修改grub.cfg文件，可先烧录img镜像到U盘，然后在U盘中修改;\n上面提到的烧录工具为Win32DiskImager(写盘工具）.exe，选择镜像和盘符，然后点击写入直到进度条满.\n最后给出我的grub.cfg文件:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 terminal_output console if serial --unit=0 --speed=115200; then terminal_input --append serial_com0 terminal_output --append serial_com0 fi set default=\u0026#34;0\u0026#34; set timeout=\u0026#34;5\u0026#34; set timeout_style=\u0026#34;menu\u0026#34; if [ -s $prefix/grubenv ]; then load_env --file $prefix/grubenv --skip-sig set has_env=\u0026#34;1\u0026#34; if [ -n \u0026#34;${saved_entry}\u0026#34; ]; then set default=\u0026#34;${saved_entry}\u0026#34; fi else set has_env=\u0026#34;0\u0026#34; echo \u0026#34;WARN: failed to load env. Default choice will NOT be saved!\u0026#34; fi function savedefault { saved_entry=\u0026#34;${chosen}\u0026#34; save_env --file $prefix/grubenv saved_entry } insmod usb_keyboard insmod part_msdos insmod ext2 insmod fat insmod linux insmod gzio set gfxmode=auto insmod vbe insmod vga # UEFI insmod efi_gop insmod efi_uga insmod font if loadfont ${prefix}/unicode.pf2 then insmod gfxterm set gfxmode=auto set gfxpayload=keep terminal_output gfxterm fi menuentry \u0026#39;RedPill DS918+ v7.1.0-42661 (USB, Verbose)\u0026#39; { savedefault set root=(hd0,msdos1) echo Loading Linux... linux /zImage HddHotplug=0 withefi console=ttyS0,115200n8 netif_num=2 syno_hdd_detect=0 syno_port_thaw=1 vender_format_version=2 sn=xxx mac1=xxx mac2=xxx earlyprintk syno_hdd_powerup_seq=1 pid=0x5678 log_buf_len=32M syno_hw_version=DS918+ vid=0xffff earlycon=uart8250,io,0x3f8,115200n8 elevator=elevator root=/dev/md0 loglevel=15 DiskIdxMap=0002 SataPortMap=22 SasIdxMap=0 echo Loading initramfs... initrd /rd.gz /custom.gz echo Starting kernel with USB boot } menuentry \u0026#39;RedPill DS918+ v7.1.0-42661 (SATA, Verbose)\u0026#39; { savedefault set root=(hd0,msdos1) echo Loading Linux... linux /zImage HddHotplug=0 withefi console=ttyS0,115200n8 synoboot_satadom=2 DiskIdxMap=00 netif_num=1 syno_hdd_detect=0 syno_port_thaw=1 SasIdxMap=0 vender_format_version=2 earlyprintk mac1=xxx syno_hdd_powerup_seq=1 pid=0x5678 log_buf_len=32M syno_hw_version=DS918+ vid=0xffff earlycon=uart8250,io,0x3f8,115200n8 sn=xxx elevator=elevator root=/dev/md0 loglevel=15 SataPortMap=1 echo Loading initramfs... initrd /rd.gz /custom.gz echo Starting kernel with SATA boot echo WARNING: SATA boot support on this platform is experimental! } 系统安装 在安装之前，需要运行synology-assistant-7.win系统版.exe安装程序，在网盘已提供，用于扫描局域网中存在的NAS;\n在制作完成U盘引导后，插入到NAS中，然后启动NAS，运行Synology Assistant，安装过程略;\n注意\n对于黑群晖，在安装过程中最好断网，即便是全洗白的(有时成功、但也有失败)，最后导致系统被锁，无限还原，在出现10分钟倒计时开始就断开与互联网的连接;\n对于初学者，提前准备1个硬盘盒(3.5寸)、多个引导U盘，当系统无限还原，那么就格式化磁盘吧，过程略;\n系统如果需要升级，需做好备份，然后找到对应的img镜像和pat文件，再尝试新U盘制作引导，由于没亲历过(只重装系统)，可参考该文章\n系统使用 在装完系统后，可以体验群晖简单实用的功能了，但其中有些注意点，可参考该系列文章:\n登录Synology账户 由于许多功能依赖于群晖账户，比如QuickConnect、ActiveInsight、DDNS等，此外还有其他的一些功能;\n群晖账户尽量在全球站注册，可参考该文章，具体原因也在其中说明;\n注册完账户后，可在群晖控制面板中登录群晖账户，然后可体验部分功能，QuickConnect需绑定电话(但不建议绑定，会导致群晖变黑)，DDNS可直接采用官方提供的域名(证书支持泛域名，较简单，但时常会失败);\nDDNS与证书续期 DDNS可查看先前我记录的DDNS踩坑经历文章，DDNS服务提供商建议采用Cloudflare，将域名的DNS服务器设为Cloudflare(CF)的，主要是为了方便之后通过acme.sh自动申请证书，经过测试采用dns_dp即腾讯的域名解析，申请不知为何原因失败，到了第二天换成dns_cf一次便成功，下面介绍整个过程;\nDDNS配置 前提条件，具备公网IPv4或IPv6，家庭的话IPv6应该都有，没的话需咨询宽带提供商，如果因为光猫配置问题，可致电询问光猫超级用户账号密码(用于将路由桥接修改为路由模式)，或者参考网上教程去破解(需注意型号问题);\n对于DDNS，首先需购买域名，然后将其DNS服务器设置为CF的，接着在系统中可以通过docker或套件中心来安装DDNS-GO;\n然后在CF中添加该域名，并在My Profile中的API Tokens分别添加API Token(用于DDNS-GO服务)和Global API Key(用于自动申请证书)\n其中，API Token中选择Create Token，模板选择Edit zone DNS，在Zone Resources中选择包含的可作用域名;Global API Key可直接查看，略;\n证书申请 需要注意几个问题，证书是否需要泛域名，证书是否频繁更新，根据需求选择采用ZeroSSL还是Letsencrypt证书提供商;\n关于泛域名，如果没有相关需求，建议采用ZeroSSL，优势是不限制申请次数;\n群晖支持采用Letsencrypt申请泛域名证书，但只为群晖提供的域名后缀提供服务，因此若不采用群晖的DDNS，且考虑到便利性，那么需要借助类似acme.sh的工具来自动申请证书，可参考该文章，具体过程如下:\n首先，需要申请证书，这里acme.sh采用dns_cf的方式，需要借助上文提到的Global API Key的Global API Key和该账户的邮箱，然后在ssh终端执行以下指令:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 你的域名 DOMAIN=\u0026#39;xxx.xxx\u0026#39; # DNS供应商 可选 dns_dp(腾讯云) dns_ali(阿里云) dns_cf 其他可查https://github.com/acmesh-official/acme.sh/wiki/dnsapi DNS=\u0026#34;dns_cf\u0026#34; #证书供应商 CERT_SERVER=\u0026#34;letsencrypt\u0026#34; CF_Key=\u0026#39;xxx\u0026#39; CF_Email=\u0026#39;xxx\u0026#39; docker run --rm \\ -v \u0026#34;/volume1/docker/acme:/acme.sh\u0026#34; \\ -e \u0026#34;CF_Key=${CF_Key}\u0026#34; -e \u0026#34;CF_Email=${CF_Email}\u0026#34; \\ neilpang/acme.sh \\ acme.sh --dns \u0026#34;${DNS}\u0026#34; \\ --server \u0026#34;${CERT_SERVER}\u0026#34; \\ --issue -d \u0026#34;${DOMAIN}\u0026#34; -d \u0026#34;*.${DOMAIN}\u0026#34; 可能由于网络或脚本版本问题，Letsencrypt证书不一定一次成功，需注意申请次数不能短时间太多，当出现Success，至此已经申请到带泛域名的证书，然后需要将证书通过acme.sh提供的群晖部署方式部署，脚本如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #群晖账号密码 SYNO_Username=\u0026#39;xxx\u0026#39; SYNO_Password=\u0026#39;xxx\u0026#39; #如果开启了双重验证请在浏览器登录时选中保存此设备，然后从COOKIE中获取did cookie SYNO_TOTP_SECRET=\u0026#34;\u0026#34; #以下群晖配置非必要不要更改 SYNO_Hostname=\u0026#34;localhost\u0026#34; # Specify if not using on localhost SYNO_Scheme=\u0026#34;http\u0026#34; SYNO_Port=\u0026#34;5000\u0026#34; # 经测试发现localhost不行，而通过网卡的IPv4可以 ipv4=\u0026#34;$(ifconfig eth0 | grep -E \u0026#39;inet addr\u0026#39; | cut -d: -f2 | awk \u0026#39;{print $1}\u0026#39; )\u0026#34; SYNO_Hostname=\u0026#34;${ipv4}\u0026#34; # Specify if not using on localhost #要添加的证书的名字，空字符串（\u0026#34;\u0026#34;）的话就是替代默认证书，一般建议使用空字符串，除非你有多个证书 SYNO_Certificate=\u0026#39;xxx\u0026#39; # 建议和域名保持一致 # 以下为acme.sh通过dsm_deploy部署到系统的必要参数 c=\u0026#34;SYNO_Username=${SYNO_Username}\u0026#34; d=\u0026#34;SYNO_Password=${SYNO_Password}\u0026#34; e=\u0026#34;SYNO_TOTP_SECRET=${SYNO_TOTP_SECRET}\u0026#34; f=\u0026#34;SYNO_Hostname=${SYNO_Hostname}\u0026#34; g=\u0026#34;SYNO_Scheme=${SYNO_Scheme}\u0026#34; h=\u0026#34;SYNO_Port=${SYNO_Port}\u0026#34; i=\u0026#34;SYNO_Certificate=${SYNO_Certificate}\u0026#34; j=\u0026#34;SYNO_DID=${SYNO_TOTP_SECRET}\u0026#34; docker run --rm \\ -v \u0026#34;/volume1/docker/acme:/acme.sh\u0026#34; \\ -e ${c} -e ${d} -e ${e} -e ${f} -e ${g} -e ${h} -e ${i} -e ${j} \\ neilpang/acme.sh \\ acme.sh --dns \u0026#34;${DNS}\u0026#34; \\ --issue -d \u0026#34;${DOMAIN}\u0026#34; -d \u0026#34;*.${DOMAIN}\u0026#34; \\ --deploy --deploy-hook synology_dsm 至此，通过acme.sh的docker容器申请证书与部署到群晖已完成，脚本参考该仓库，修改后的脚本如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/bin/bash # 你的域名 DOMAIN=\u0026#39;xxx\u0026#39; #证书供应商 CERT_SERVER=\u0026#39;letsencrypt\u0026#39; #DNS供应商 可选 dns_dp(腾讯云) dns_ali(阿里云) dns_cf 其他可查https://github.com/acmesh-official/acme.sh/wiki/dnsapi DNS=\u0026#34;dns_cf\u0026#34; #群晖账号密码 SYNO_Username=\u0026#39;xxx\u0026#39; SYNO_Password=\u0026#39;xxx\u0026#39; #如果开启了双重验证请在浏览器登录时选中保存此设备，然后从COOKIE中获取did cookie SYNO_TOTP_SECRET=\u0026#34;\u0026#34; #以下群晖配置非必要不要更改 SYNO_Hostname=\u0026#34;localhost\u0026#34; # Specify if not using on localhost SYNO_Scheme=\u0026#34;http\u0026#34; SYNO_Port=\u0026#34;5000\u0026#34; ipv4=\u0026#34;$(ifconfig eth0 | grep -E \u0026#39;inet addr\u0026#39; | cut -d: -f2 | awk \u0026#39;{print $1}\u0026#39; )\u0026#34; SYNO_Hostname=\u0026#34;${ipv4}\u0026#34; # Specify if not using on localhost #要添加的证书的名字，空字符串（\u0026#34;\u0026#34;）的话就是替代默认证书，一般建议使用空字符串，除非你有多个证书 SYNO_Certificate=\u0026#39;xxx\u0026#39; #以下三选一 #DNSPOD.CN 腾讯云 DP_Id=\u0026#39;\u0026#39; DP_Key=\u0026#39;\u0026#39; #阿里云 Ali_Key=\u0026#39;\u0026#39; Ali_Secret=\u0026#39;\u0026#39; #CF CF_Key=\u0026#39;xxx\u0026#39; CF_Email=\u0026#39;xxx\u0026#39; case $DNS in \u0026#34;dns_dp\u0026#34;) a=\u0026#34;DP_Id=${DP_Id}\u0026#34;\u0026amp;\u0026amp;b=\u0026#34;DP_Key=${DP_Key}\u0026#34; ;; \u0026#34;dns_ali\u0026#34;) a=\u0026#34;Ali_Key=${Ali_Key}\u0026#34;\u0026amp;\u0026amp;b=\u0026#34;Ali_Secret=${Ali_Secret}\u0026#34; ;; \u0026#34;dns_cf\u0026#34;) a=\u0026#34;CF_Key=${CF_Key}\u0026#34;\u0026amp;\u0026amp;b=\u0026#34;CF_Email=${CF_Email}\u0026#34; ;; esac c=\u0026#34;SYNO_Username=${SYNO_Username}\u0026#34; d=\u0026#34;SYNO_Password=${SYNO_Password}\u0026#34; e=\u0026#34;SYNO_TOTP_SECRET=${SYNO_TOTP_SECRET}\u0026#34; f=\u0026#34;SYNO_Hostname=${SYNO_Hostname}\u0026#34; g=\u0026#34;SYNO_Scheme=${SYNO_Scheme}\u0026#34; h=\u0026#34;SYNO_Port=${SYNO_Port}\u0026#34; i=\u0026#34;SYNO_Certificate=${SYNO_Certificate}\u0026#34; j=\u0026#34;SYNO_DID=${SYNO_TOTP_SECRET}\u0026#34; # 申请证书 docker run --rm \\ -v \u0026#34;/volume1/docker/acme:/acme.sh\u0026#34; \\ -e ${a} -e ${b} \\ neilpang/acme.sh \\ acme.sh --dns \u0026#34;${DNS}\u0026#34; \\ --server \u0026#34;${CERT_SERVER}\u0026#34; \\ --renew -d \u0026#34;${DOMAIN}\u0026#34; -d \u0026#34;*.${DOMAIN}\u0026#34; # --issue -d \u0026#34;${DOMAIN}\u0026#34; -d \u0026#34;*.${DOMAIN}\u0026#34; # 部署证书到群晖 docker run --rm \\ -v \u0026#34;/volume1/docker/acme:/acme.sh\u0026#34; \\ -e ${c} -e ${d} -e ${e} -e ${f} -e ${g} -e ${h} -e ${i} -e ${j} \\ neilpang/acme.sh \\ acme.sh --dns \u0026#34;${DNS}\u0026#34; \\ --issue -d \u0026#34;${DOMAIN}\u0026#34; -d \u0026#34;*.${DOMAIN}\u0026#34; \\ --deploy --deploy-hook synology_dsm 如果想要定时更新证书，可在控制面板中的任务计划添加任务，由于有些指令与目录访问需要高权限，比如docker指令和某些路径，以root身份执行，每月执行一次;\n但仍存在些小问题，比如两步验证，开启了两步验证，但没有配置SYNO_TOTP_SECRET参数，执行脚本仍可以成功;采用腾讯云的api-id和api-key方式申请Letsencrypt证书始终不成功，在相关Issue中说明需更新acme.sh或换网络等，具体没尝试过.\nSSO单点登录 琢磨良久，没成功，暂时略，后续补充.\n参考 http://k.8x6x.com/thread-72641-1-1.html\nhttps://www.openos.org/threads/diskidxmap-sataportmap-sasidxmap.3675/\nhttps://blog.csdn.net/qq_35379989/article/details/129287254\nhttps://post.smzdm.com/p/a0q4zgx9/p4/?sort_tab=hot/#comments\nhttps://www.ainas.cc:88/?page_id=8\nhttps://www.ainas.cc:88/?p=572\nhttps://post.smzdm.com/p/a6d5dl6e/\n2023-06-28 首次更新\n","date":"2023-06-28T10:21:51+08:00","image":"https://adja.com.cn/p/synology-user-experience/cover_hu_40206b28c7d9a21c.jpg","permalink":"https://adja.com.cn/p/synology-user-experience/","title":"黑群晖使用体验"},{"content":"通过Jenkins自动化构建 续之前Jenkins相关的实验，这次的服务复杂一些，docker-compose.yml的文件包它包含7个service.\n项目概览 项目是前后端分离项目，后端是采用SpringBoot的多模块项目，项目结构如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 +---backend # 后端 | +---src | \\---target +---frontend # 前端 | +---dist # 前端生成文件 | \\---src +---others # 后端依赖的模块或拓展功能 | +---mqtt # mqtt的身份验证模块 | +---src | \\---target +---data # 数据库建表及数据，配置 | +---conf # 配置 | +---init # 用于mysql镜像初始化数据，控制多个sql文件执行顺序 | \\---sql # sql语句 +---conf # 配置 | +---emqx # mqtt相关配置 | \\---nginx # nginx配置 +---dockerfile # 构建自定义镜像的文件 +---shell # 脚本 \\---docker-compose.yml # 所有服务构建配置 问题 Jenkins是通过docker构建运行的，此次自动化构建采用Pipeline进行，接下来介绍中间遇到的各种问题，仅供参考;\nPipeline无法构建前端 通过日志发现是找不到npm指令，由于是采用的nvm对node进行管理，参考网上装nodejs插件文章也无法解决，一直报错 /usr/bin/env: node: No such file or directory;\n最后将nvm安装目录及/etc/profile.d/nvm.sh挂载到Jenkins，在前端构建阶段通过source指令使nvm指令生效，然后切换到对应的nodejs版本，如此也没必要安装nodejs插件了，pipeline部分如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 stage(\u0026#39;build-frontend\u0026#39;) { steps { dir(\u0026#34;./frontend\u0026#34;) { sh \u0026#39;\u0026#39;\u0026#39; source /etc/profile.d/nvm.sh nvm use 16.15.0 npm cache clean –force npm cache verify if [ -f dist ]; then rm dist -rf; fi; pnpm config get registry pnpm config set registry https://registry.npmmirror.com/ pnpm install pnpm run build:prod \u0026#39;\u0026#39;\u0026#39; } } } 注意：类似找不到指令的报错都可以通过挂载安装目录和使配置生效的方法来解决.\n通过ssh远程操作 在全局凭据上配置好私钥后，在Pipeline最好通过插件(SSH Pipeline Steps)进行ssh，如果直接采用密码，日志上会回显，参考如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 steps { withCredentials(bindings: [ \\ sshUserPrivateKey(credentialsId: \u0026#39;private-key\u0026#39;, keyFileVariable: \u0026#39;primaryKeyVar\u0026#39;, passphraseVariable: \u0026#39;pwdVar\u0026#39;, usernameVariable: \u0026#39;userVar\u0026#39;)]) { script { def remote = [:] remote.name = \u0026#39;192.168.137.2\u0026#39; remote.host = \u0026#39;192.168.137.2\u0026#39; remote.user = userVar remote.identityFile = primaryKeyVar remote.allowAnyHosts = true stage(\u0026#39;Remote SSH\u0026#39;) { sshCommand remote: remote, command: \u0026#34;mkdir -p ${REMOTE_WORKDIR}/frontend\u0026#34; // 前端打包文件 sshPut remote: remote, from: \u0026#34;./frontend/dist\u0026#34;, into: \u0026#34;${REMOTE_WORKDIR}/frontend\u0026#34; // 显示传输所有文件 sshCommand remote: remote, command: \u0026#34;ls -lrt ${REMOTE_WORKDIR}/**\u0026#34; } } } } 控制服务启动顺序 在docker-compose.yml如果需要控制启动顺序，单靠depends_on是不足的，它仅仅控制启动顺序，但不保证服务启动成功才启动下一个;\n参考文章说，通过挂载wait-for-it.sh，容器启动通过执行该脚本判断依赖服务是否启动，指导启动成功才运行本服务，也可参考这篇文章;\n然而如果镜像已经设定了entrypoint，那么还需要了解该镜像的entrypoint做了什么，只需要将wait-for-it.sh脚本添加到该镜像的entrypoint指令之前;\n其中wait-for-it.sh参考https: //github.com/vishnubob/wait-for-it，我将该文件改名为entrypoint.sh放入shell目录中，挂载到容器，设定CMD或者entrypoint即可，参考如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 service: backend: # 后端主模块 build: context: . dockerfile: dockerfile/backend-Dockerfile image: backend_app container_name: prod-backend-app ports: - \u0026#34;13245:13245\u0026#34; # 端口映射 environment: TZ: Asia/Shanghai # 时区 PORT: 13245 # 容器运行端口 PROFILE: prod # 运行环境，默认 volumes: - ./shell/entrypoint.sh:/entrypoint.sh depends_on: - emq - influx 名为backend的service的Dockerfile文件改名为backend-Dockerfile放入dockerfile路径中，由于后端依赖于mysql、redis，所以内容如下:\n1 2 3 4 5 FROM openjdk:8-jdk ADD backend/target/*.jar /app.jar CMD bash /entrypoint.sh mysqldb:3306 -t 30 -- echo \u0026#34;mysql started\u0026#34; \\ \u0026amp;\u0026amp; bash /entrypoint.sh redisdb:6379 -t 20 -- echo \u0026#34;redisdb started\u0026#34; \\ \u0026amp;\u0026amp; java -jar -Dfile.encoding=utf-8 -Dserver.port=${PORT} -Dspring.profiles.active=${PROFILE} /app.jar 消息队列emqx配置 我采用的emqx版本为4.4.2，参考了官网通过环境变量的方式配置，其中emq_web_hook插件有效但emq_http_auth插件始终不生效;\n参考了Emqx的官方github上的issue也没解决，最后还得靠挂载emqx的配置才解决;\n然后，还有个问题待解决，由于emqx用了http认证插件，我单独将认证的auth模块拿出来作为一个service，这时应该是auth启动完才启动emqx，但后端service在启动之前是不会连emq，emq也就不会用到auth模块的认证接口，便没有自定义构建emq镜像，但该问题还得解决;\n参考我写的emq服务:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 service: emq: user: root restart: always container_name: prod-emqx image: emqx/emqx:4.4.2 ports: - \u0026#34;18083:18083\u0026#34; - \u0026#34;1883:1883\u0026#34; - \u0026#34;8083:8083\u0026#34; - \u0026#34;8084:8084\u0026#34; - \u0026#34;8883:8883\u0026#34; volumes: - /etc/localtime:/etc/localtime - /root/docker/emqx/log:/opt/emqx/log - ./conf/emqx/emqx_auth_http.conf:/opt/emqx/etc/plugins/emqx_auth_http.conf - ./conf/emqx/emqx_web_hook.conf:/opt/emqx/etc/plugins/emqx_web_hook.conf # TODO:存在bug，emq依赖于auth的http认证服务，取消以下两行注释会无法运行，发现emqx自带entrypoint和CMD # - ./shell/entrypoint.sh:/entrypoint.sh #entrypoint: bash /entrypoint.sh auth:13244 -t 50 -- echo \u0026#34;auth started\u0026#34; \u0026amp;\u0026amp; /opt/emqx/bin/emqx foreground; environment: EMQX_ALLOW_ANONYMOUS: false # allow_anonymous EMQX_LOADED_PLUGINS: \u0026#34;emqx_management,emqx_auth_http,emqx_dashboard,emqx_web_hook\u0026#34; EMQX_DASHBOARD__DEFAULT_USER__LOGIN: root EMQX_DASHBOARD__DEFAULT_USER__PASSWORD: 12345 networks: app_net: ipv4_address: 172.31.0.10 depends_on: - auth links: - auth 前端构建成功但无法访问或请求本地 参考网上，大多采用nginx作为基础镜像构建新镜像，再配置nginx的转发规则;\n找到一篇不错的文章，它没有构建新镜像，而是通过挂载前端文件和配置文件实现，节约了构建新镜像所需的时间和空间，文章地址为:https://juejin.cn/post/6844903837774397447;\n自己配置的nginx.conf如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 server { listen 13246; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } #Location配置 location /api/ { rewrite /api/(.*) /$1 break; proxy_pass http://backend:13245; } } 由于对nginx没有深入学过，遇到各种问题，经过反复尝试后，最终达到了预期.\n补充些依赖配置 项目基于Vue3和SpringBoot，采用Jenkins的容器进行自动化构建和部署，然而也不能什么软件都装在容器中，最好的办法就是宿主机装常用工具软件，再挂载到容器中;\n安装docker 1 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 安装jdk8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 rm /tmp/jdk*.tar.gz -f wget https://repo.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz -P /tmp ls -lht /tmp/ | grep jdk mkdir -p /usr/local/java/ tar -zxf /tmp/jdk-8u202-linux-x64.tar.gz -C /usr/local/java/ \u0026amp;\u0026amp; ls /usr/local/java/ -l # 添加环境jdk1.8环境变量 cat \u0026gt; /etc/profile.d/java.sh \u0026lt;\u0026lt;EOF export JAVA_HOME=/usr/local/java/jdk1.8.0_202 export JRE_HOME=\\${JAVA_HOME}/jre export CLASSPATH=.:\\${JAVA_HOME}/lib:\\${JRE_HOME}/lib export PATH=\\${JAVA_HOME}/bin:\\$PATH EOF source /etc/profile.d/java.sh ln -s ${JAVA_HOME}/bin/java /usr/bin/java java -version 安装Maven maven镜像有许多失效了，建议还是网上找找，下方的maven版本号改成对应的，脚本仅作参考;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 maven_version=3.9.0 rm /tmp/*maven*.tar.gz -rf #wget https://dlcdn.apache.org/maven/maven-3/3.9.0/binaries/apache-maven-3.9.0-bin.tar.gz -P /tmp wget https://mirrors.aliyun.com/apache/maven/maven-3/3.9.0/binaries/apache-maven-3.9.0-bin.tar.gz -P /tmp ls -lht /tmp/ | grep maven mkdir -p /usr/local/maven/ tar -zxf /tmp/apache-maven-*.tar.gz -C /usr/local/maven/ \u0026amp;\u0026amp; ls /usr/local/maven/ -l # 添加Maven环境变量 cat \u0026gt; /etc/profile.d/maven.sh \u0026lt;\u0026lt; EOF export MAVEN_VERSION=\u0026#34;${maven_version}\u0026#34; export M2_HOME=/usr/local/maven/apache-maven-\\${MAVEN_VERSION} export MAVEN_HOME=/usr/local/maven/apache-maven-3.9.0 export PATH=\\${MAVEN_HOME}/bin:\\${PATH} EOF chmod +x /etc/profile.d/maven.sh source /etc/profile.d/maven.sh mvn -version 安装nvm 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 nvm_version=0.39.3 rm /tmp/v${nvm_version}.tar.gz -rf wget https://github.com/nvm-sh/nvm/archive/refs/tags/v${nvm_version}.tar.gz -P /tmp ls -lht /tmp/ | grep \u0026#34;v${nvm_version}.tar.gz\u0026#34; mkdir -p /usr/local/nvm/ tar -zxf /tmp/v${nvm_version}.tar.gz -C /usr/local/nvm/ \u0026amp;\u0026amp; ls /usr/local/nvm/ -l # 添加nvm环境变量 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/profile.d/nvm.sh export NVM_VERSION=\u0026#34;${nvm_version}\u0026#34; export NVM_DIR=\u0026#34;/usr/local/nvm/nvm-\\${NVM_VERSION}\u0026#34; [ -s \u0026#34;\\$NVM_DIR/nvm.sh\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;\\$NVM_DIR/nvm.sh\u0026#34; # This loads nvm [ -s \u0026#34;\\$NVM_DIR/bash_completion\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;\\$NVM_DIR/bash_completion\u0026#34; EOF chmod +x /etc/profile.d/nvm.sh source /etc/profile.d/nvm.sh nvm version 安装docker-compose 建议docker-compose去github官网下，国内大多可下的版本太旧了;\n1 2 3 curl -L https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose docker-compose -v 总结 通过将新学的Jenkins自动化技术应用于项目中，可以极大地节省时间，运维不必重复地手动部署，测试成了开发的一部分，只需编写测试脚本，开发人员每次代码提交会自动执行测试脚本，再通过ssh部署至远程，由传统的一个一个阶段地开发，不能直接跳过某个阶段，到如今开发能够迅速测试并投入生产得到反馈，效率倍增，或许这就是CI/CD概念及工具流行的原因。\n参考 https://github.com/vishnubob/wait-for-it\nhttps://www.cnblogs.com/wang_yb/p/9400291.html\nhttps://juejin.cn/post/6844903837774397447\nhttps://juejin.cn/post/7095729903684829191\n2023-02-16 更新\n2023-02-26 添加依赖的安装配置\n2024-07-06 支持英文\n","date":"2023-02-16T15:10:34+08:00","image":"https://adja.com.cn/p/automated-build-via-jenkins/cover_hu_ef3c10312f6a2c51.jpg","permalink":"https://adja.com.cn/p/automated-build-via-jenkins/","title":"通过Jenkins自动化构建"},{"content":"破解光猫超级用户密码 首先我强调光猫型号为HS8545M5，软件版本为V5R020C00S200；\n由于需要光猫出场时默认为路由模式，我需要将其修改为桥接模式，而光猫背面的user用户没有权限修改，因此需要获取超级用户权限。\n光猫telnet使能 光猫没有开启telnet服务，需要工具进行破解，破解工具的下载链接在最后；\n先下载破解工具，接着拔掉光纤，重启光猫，通过宽带线把电脑与光猫连接，打开ONT维修使能工具；\n选择维修使能，点击刷新，然后启动; 当“当前成功总数”变为1后，点击停止，结果类似下面截图;\n打开命令行，测试telnet能否连接成功，当出现找不到命令时，开启windows的telnet服务;\n1 telnet 192.168.1.1 然后输入用户名root;密码尝试下Hw8@cMcc或者adminHW,成功的话结果如下：\n获取用户名及密码密文 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 WAP\u0026gt;su success! SU_WAP\u0026gt;shell BusyBox v1.30.1 () built-in shell (ash) Enter \u0026#39;help\u0026#39; for a list of built-in commands. profile close core dump WAP(Dopra Linux) # ls bin dev init linuxrc root sys var boot etc lib mnt sbin tmp bundle html libexec proc share usr WAP(Dopra Linux) # cd /mnt/jffs2/ WAP(Dopra Linux) # ls CfgFile_Backup dypack_debug mount_ok CfgwithoutlineD factory_file mount_osgi_ok DHCPlasterrwan1 fsok nffruntimes DHCPlasterrwan5 ftvoipcfgstate oldcrc FTCRC hard_version onlinecounter InformFlag hw_boardinfo ontstatusfile TelnetEnable hw_boardinfo.bak optic_init_par.bin Updateflag_bak hw_bootcfg.xml ppplasterr258 UpnpExpandFirstInit hw_ctree.xml ppplasterr259 V5_TypeWord_FLAG hw_ctree_bak.xml reboot_bind_tag app hw_default_ctree.xml reboot_info asan_test hw_default_ctree2.xml recovername backup_ok hw_hardinfo_feature request_ddr board_type hwflashlog.bin request_ddr_inner bob_type hwkeyinfogetlog.bin resetkey ceaseadv.conf hwnfflog.bin restore certs hwontdebuglogctrl.bin result_ddr customize hwontdebuglogdata.bin scflie_0 customize.txt hwontlog.bin scflie_1 customizepara.txt keyreleasecount.txt smooth_finish cwmp_rebootsave kmc_need_backup typeword dhcp6c kmc_store_A upgrade_info.xml_back dhcp_data_a kmc_store_B xmlcfgerrorcode dhcp_lastip lastsysinfo.tar.gz dhcpc main_version WAP(Dopra Linux) # cp /mnt/jffs2/hw_ctree.xml /mnt/jffs2/mycfg.xml.gz WAP(Dopra Linux) # aescrypt2 1 mycfg.xml.gz tem WAP(Dopra Linux) # gzip -d mycfg.xml.gz WAP(Dopra Linux) # grep WebUserInfoInstance mycfg.xml \u0026lt;X_HW_WebUserInfoInstance InstanceID=\u0026#34;1\u0026#34; ModifyPasswordFlag=\u0026#34;0\u0026#34; UserName=\u0026#34;user\u0026#34; Password=\u0026#34;$2sN}QKqrgY(,w8^GHpW7)$|L3MQ)tWIkZv5Na2Z1E$\u0026#34; UserLevel=\u0026#34;1\u0026#34; Enable=\u0026#34;1\u0026#34; Alias=\u0026#34;cpe-1\u0026#34;/\u0026gt; \u0026lt;X_HW_WebUserInfoInstance InstanceID=\u0026#34;2\u0026#34; ModifyPasswordFlag=\u0026#34;1\u0026#34; UserName=\u0026#34;CMCCAdmin\u0026#34; Password=\u0026#34;$2I3^R(k3[.)B9I4E8:S!DF!Q$ULd6S(U7RRH^2]2-=Nxs\u0026amp;amp;S`J6))+2$S8\u0026amp;quot;\u0026amp;apos;j\u0026amp;amp;$\u0026#34; UserLevel=\u0026#34;0\u0026#34; Enable=\u0026#34;1\u0026#34; Alias=\u0026#34;cpe-2\u0026#34; PassMode=\u0026#34;0\u0026#34;/\u0026gt; WAP(Dopra Linux) # success! SU_WAP\u0026gt; 找到关键字user与password部分;\n上图中CMCCAdmin用户密码密文为：$2I3^R(k3[.)B9I4E8:S!DF!Q$ULd6S(U7RRH^2]2-=Nxs\u0026amp;amp;S`J6))+2$S8\u0026amp;quot;\u0026amp;apos;j\u0026amp;amp;$\n打开华为二次密码破解工具S1S2语音全鉴密.zip中的huawei.exe，在密文解密中输入，尝试3种解密，得出密码为CMCCAdminFf2IrXFt\n使用超级用户登录光猫 用户名CMCCAdmin，密码CMCCAdminFf2IrXFt，发现可以修改连接模式了;\n文件链接：https://pan.baidu.com/s/101GrTj53T4RaIpc0h4KAoQ\n提取码：adja\n参考 https://www.eaglemoe.com/archives/216 2022-06-18 更新\n","date":"2022-06-18T15:43:59+08:00","image":"https://adja.com.cn/p/crack-the-optical-modem-superuser-password/cover_hu_46fa2d809497bc3f.jpg","permalink":"https://adja.com.cn/p/crack-the-optical-modem-superuser-password/","title":"破解光猫超级用户密码"}]